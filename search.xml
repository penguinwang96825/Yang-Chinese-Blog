<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>魔術方塊LBL解法</title>
      <link href="/Yang-Chinese-Blog/post/1635b73a.html"/>
      <url>/Yang-Chinese-Blog/post/1635b73a.html</url>
      
        <content type="html"><![CDATA[<p>魔術方塊，這個1974年由Ernő Rubik所發明的智力遊戲，迄今仍吸引著全球數百萬愛好者。解開魔術方塊的過程不僅能增強記憶與解決問題的能力，還能帶來極大的樂趣和成就感。因此，我決定撰寫這個部落格來分享我解魔術方塊的心得與技巧，希望能幫助初學者輕鬆入門，並為那些尋求提高解題速度的人提供策略。</p><h1 id="國際轉動代號"><a href="#國際轉動代號" class="headerlink" title="國際轉動代號"></a>國際轉動代號</h1><p>轉動代號在魔術方塊社群中起著一種普遍語言的作用，全球的玩家都使用這些代號來溝通解題的步驟和方法，甚至在比賽中也以這種代號來出題！因此，當我們希望進一步提升自己的技能和實力時，學會這些轉動代號變得極其關鍵，因為只有理解這些代號，我們才能夠明白其他玩家分享的解題公式應如何操作。</p><h2 id="外層轉動符號"><a href="#外層轉動符號" class="headerlink" title="外層轉動符號"></a>外層轉動符號</h2><table>    <thead>        <tr>        <th>轉動代號</th>        <th>圖例</th>        <th>轉動代號</th>        <th>圖例</th>        </tr>    </thead>    <tbody>        <tr>        <td class="align-middle text-center" style="text-align: center;">R <span class="text-muted small">(Right)</span></td>        <td><img src="https://chiacube.tw/images/Rotate/rotate_R.svg" alt="Rotate_R" style="width: 100px; height: 100px; min-width:80px; max-width: 100%"></td>        <td class="align-middle text-center" style="text-align: center;">R'</td>        <td><img src="https://chiacube.tw/images/Rotate/rotate_R'.svg" alt="Rotate_R" style="width: 100px; height: 100px; min-width:80px; max-width: 100%"></td>        </tr>        <tr>        <td class="align-middle text-center" style="text-align: center;">U <span class="text-muted small">(Up)</span></td>        <td><img src="https://chiacube.tw/images/Rotate/rotate_U.svg" alt="Rotate_R" style="width: 100px; height: 100px; max-width: 100%"></td>        <td class="align-middle text-center" style="text-align: center;">U'</td>        <td><img src="https://chiacube.tw/images/Rotate/rotate_U'.svg" alt="Rotate_R" style="width: 100px; height: 100px; max-width: 100%"></td>        </tr>        <tr>        <td class="align-middle text-center" style="text-align: center;">F <span class="text-muted small">(Front)</span></td>        <td><img src="https://chiacube.tw/images/Rotate/rotate_F.svg" alt="Rotate_R" style="width: 100px; height: 100px; max-width: 100%"></td>        <td class="align-middle text-center" style="text-align: center;">F'</td>        <td><img src="https://chiacube.tw/images/Rotate/rotate_F'.svg" alt="Rotate_R" style="width: 100px; height: 100px; max-width: 100%"></td>        </tr>        <tr>        <td class="align-middle text-center" style="text-align: center;">L <span class="text-muted small">(Left)</span></td>        <td><img src="https://chiacube.tw/images/Rotate/rotate_L.svg" alt="Rotate_R" style="width: 100px; height: 100px; max-width: 100%"></td>        <td class="align-middle text-center" style="text-align: center;">L'</td>        <td><img src="https://chiacube.tw/images/Rotate/rotate_L'.svg" alt="Rotate_R" style="width: 100px; height: 100px; max-width: 100%"></td>        </tr>        <tr>        <td class="align-middle text-center" style="text-align: center;">D <span class="text-muted small">(Down)</span></td>        <td><img src="https://chiacube.tw/images/Rotate/rotate_D.svg" alt="Rotate_R" style="width: 100px; height: 100px; max-width: 100%"></td>        <td class="align-middle text-center" style="text-align: center;">D'</td>        <td><img src="https://chiacube.tw/images/Rotate/rotate_D'.svg" alt="Rotate_R" style="width: 100px; height: 100px; max-width: 100%"></td>        </tr>        <tr>        <td class="align-middle text-center" style="text-align: center;">B <span class="text-muted small">(Back)</span></td>        <td><img src="https://chiacube.tw/images/Rotate/rotate_B.svg" alt="Rotate_R" style="width: 100px; height: 100px; max-width: 100%"></td>        <td class="align-middle text-center" style="text-align: center;">B'</td>        <td><img src="https://chiacube.tw/images/Rotate/rotate_B'.svg" alt="Rotate_R" style="width: 100px; height: 100px; max-width: 100%"></td>        </tr>    </tbody></table><p>除此之外，為了明確的表示更多的方向與動作，在這些英文的符號後面會出現三種情況：</p><ul><li>‘：代表為動作符號逆時針旋轉。例如：R’</li><li>2：代表所指的這個動作要旋轉180度，即轉動兩步(次)。例如：R2</li><li>w：代表所指的這個動作，一次要轉動兩層。例如：Rw</li></ul><h2 id="整顆旋轉代號"><a href="#整顆旋轉代號" class="headerlink" title="整顆旋轉代號"></a>整顆旋轉代號</h2><table class="table table-bordered bg-BgGray text-center text-nowrap">    <thead>        <tr>        <th>轉動代號</th>        <th>圖例</th>        <th>轉動代號</th>        <th>圖例</th>        </tr>    </thead>    <tbody>        <tr>        <td class="align-middle" style="text-align: center;">x</td>        <td><img src="https://chiacube.tw/images/Rotate/rotate_x.svg" alt="Rotate_x" style="width: 100px; height: 100px; min-width:80px; max-width: 100%"></td>        <td class="align-middle" style="text-align: center;">x'</td>        <td><img src="https://chiacube.tw/images/Rotate/rotate_x'.svg" alt="Rotate_x'" style="width: 100px; height: 100px; min-width:80px; max-width: 100%"></td>          </tr>        <tr>        <td class="align-middle" style="text-align: center;">y</td>        <td><img src="https://chiacube.tw/images/Rotate/rotate_y.svg" alt="Rotate_y" style="width: 100px; height: 100px; min-width:80px; max-width: 100%"></td>        <td class="align-middle" style="text-align: center;">y'</td>        <td><img src="https://chiacube.tw/images/Rotate/rotate_y'.svg" alt="Rotate_y'" style="width: 100px; height: 100px; min-width:80px; max-width: 100%"></td>        </tr>        <tr>        <td class="align-middle" style="text-align: center;">z</td>        <td><img src="https://chiacube.tw/images/Rotate/rotate_z.svg" alt="Rotate_z" style="width: 100px; height: 100px; min-width:80px; max-width: 100%"></td>        <td class="align-middle" style="text-align: center;">z'</td>        <td><img src="https://chiacube.tw/images/Rotate/rotate_z'.svg" alt="Rotate_z'" style="width: 100px; height: 100px; min-width:80px; max-width: 100%"></td>        </tr>    </tbody></table><h2 id="中層轉動代號"><a href="#中層轉動代號" class="headerlink" title="中層轉動代號"></a>中層轉動代號</h2><table class="table table-bordered bg-BgGray text-center text-nowrap">    <thead>        <tr>            <th>轉動代號</th>            <th>圖例</th>            <th>轉動代號</th>            <th>圖例</th>        </tr>    </thead>    <tbody>        <tr>            <td class="align-middle" style="text-align: center;">M</td>            <td><img src="https://chiacube.tw/images/Rotate/rotate_M.svg" alt="Rotate_M" style="width: 100px; height: 100px; min-width:80px; max-width: 100%"></td>            <td class="align-middle" style="text-align: center;">M'</td>            <td><img src="https://chiacube.tw/images/Rotate/rotate_M'.svg" alt="Rotate_M'" style="width: 100px; height: 100px; min-width:80px; max-width: 100%"></td>        </tr>        <tr>            <td class="align-middle" style="text-align: center;">E</td>            <td><img src="https://chiacube.tw/images/Rotate/rotate_E.svg" alt="Rotate_E" style="width: 100px; height: 100px; min-width:80px; max-width: 100%"></td>            <td class="align-middle" style="text-align: center;">E'</td>            <td><img src="https://chiacube.tw/images/Rotate/rotate_E'.svg" alt="Rotate_E'" style="width: 100px; height: 100px; min-width:80px; max-width: 100%"></td>        </tr>        <tr>            <td class="align-middle" style="text-align: center;">S</td>            <td><img src="https://chiacube.tw/images/Rotate/rotate_S.svg" alt="Rotate_S" style="width: 100px; height: 100px; min-width:80px; max-width: 100%"></td>            <td class="align-middle" style="text-align: center;">S'</td>            <td><img src="https://chiacube.tw/images/Rotate/rotate_S'.svg" alt="Rotate_S'" style="width: 100px; height: 100px; min-width:80px; max-width: 100%"></td>        </tr>    </tbody></table><h1 id="LBL"><a href="#LBL" class="headerlink" title="LBL"></a>LBL</h1><p>LBL (Layer-By-Layer)解法是解魔術方塊中最基本也是最適合初學者學習的一種方法。這種方法按照層次逐層解開魔術方塊，讓解題者能夠較容易地理解和記憶所需的算法。步驟大致區分如下：</p><ol><li>第一層</li><li>第二層 (F2L)</li><li>第三層十字 (OLL)</li><li>第三層頂面 (OLL)</li><li>第三層頂層角塊 (PLL)</li><li>第三層頂層邊塊 (PLL)</li></ol><p>這邊我們會直接略過第一層，然後從第二層的公式開始教起。</p><h1 id="F2L"><a href="#F2L" class="headerlink" title="F2L"></a>F2L</h1><p>F2L (First 2 Layers)是LBL的第二個步驟，也就是將第一層的角塊和第二層的邊塊一起解好的技術。</p><table width="100%">  <thead>    <tr>      <th width="33%">I</th>      <th width="33%">II</th>      <th width="33%">III</th>    </tr>  </thead>  <tbody>    <tr>      <!-- <td width="33%"><img src="http://cube.rider.biz/visualcube.php?fmt=svg&size=150&pzl=3&fc=nnnnnnnrnnnnnrnrrrnbnnbnbbbwwwwwwwwwoooooooooggggggggg"/></td> -->      <td width="33%"><img src="/Yang-Chinese-Blog/post/1635b73a/1.png"/></td>      <!-- <td width="33%"><img src="http://cube.rider.biz/visualcube.php?fmt=svg&size=150&pzl=3&fc=nnnnnbnnnnrnnrnrrrnnnnbnbbbwwwwwwwwwoooooooooggggggggg"/></td> -->      <td width="33%"><img src="/Yang-Chinese-Blog/post/1635b73a/2.png"/></td>      <!-- <td width="33%"><img src="http://cube.rider.biz/visualcube.php?fmt=svg&size=150&pzl=3&fc=nnnnnnnnnnnnbrnrrrnnnnbrbbbwwwwwwwwwoooooooooggggggggg"/></td> -->      <td width="33%"><img src="/Yang-Chinese-Blog/post/1635b73a/3.png"/></td>    </tr>    <tr>      <td width="33%" style="text-align: center;"><strong>F U F U F U' F' U' F'</strong></td>      <td width="33%" style="text-align: center;"><strong>R' U' R' U' R' U R U R</strong></td>      <td width="33%" style="text-align: center;"><strong>(R U U R' U)2 F' U' F</strong></td>    </tr>  </tbody></table><h1 id="OLL"><a href="#OLL" class="headerlink" title="OLL"></a>OLL</h1><p>OLL (Orientation of the Last Layer)是魔術方塊解法中的一個重要階段。這一階段的目的是通過一系列的旋轉公式，調整最後一層的所有方塊，使頂面的顏色統一。這涉及到旋轉方塊使其頂面的顏色與魔術方塊的頂面顏色一致，而不關心方塊之間的相對位置，位置的調整留待PLL階段處理。為了減少需要記憶的公式數量，我選擇使用兩階段OLL，這涉及到使用更少的公式來進行兩次操作。首先是形成一個頂面十字，然後再將其餘方塊調整到正確的方向。</p><h2 id="OLL第一階段"><a href="#OLL第一階段" class="headerlink" title="OLL第一階段"></a>OLL第一階段</h2><table width="100%">  <thead>    <tr>      <th width="33%">邊塊單點</th>      <th width="33%">邊塊直線</th>      <th width="33%">邊塊L形</th>    </tr>  </thead>  <tbody>    <tr>      <!-- <td width="33%"><img src="http://cube.rider.biz/visualcube.php?fmt=svg&size=150&pzl=3&bg=t&view=plan&fd=nnnnunnnnnnnnnnnnnnnnnnnnnndddddddddnnnnnnnnnnnnnnnnnn"/></td> -->      <td width="33%"><img src="/Yang-Chinese-Blog/post/1635b73a/oll-1-1.png"/></td>      <!-- <td width="33%"><img src="http://cube.rider.biz/visualcube.php?fmt=svg&size=150&pzl=3&bg=t&view=plan&fd=nnnuuunnnnnnnnnnnnnnnnnnnnndddddddddnnnnnnnnnnnnnnnnnn"/></td> -->      <td width="33%"><img src="/Yang-Chinese-Blog/post/1635b73a/oll-1-2.png"/></td>      <!-- <td width="33%"><img src="http://cube.rider.biz/visualcube.php?fmt=svg&size=150&pzl=3&bg=t&view=plan&fd=nnnnuununnnnnnnnnnnnnnnnnnndddddddddnnnnnnnnnnnnnnnnnn"/></td> -->      <td width="33%"><img src="/Yang-Chinese-Blog/post/1635b73a/oll-1-3.png"/></td>    </tr>    <tr>      <td width="33%" style="text-align: center;"><strong>F (R U R' U') S (R U R' U') Fw'</strong></td>      <td width="33%" style="text-align: center;"><strong>F (R U R' U') F'</strong></td>      <td width="33%" style="text-align: center;"><strong>Fw (R U R' U') Fw'</strong></td>    </tr>  </tbody></table><h2 id="OLL第二階段"><a href="#OLL第二階段" class="headerlink" title="OLL第二階段"></a>OLL第二階段</h2><table width="100%">  <thead>    <tr>      <th width="50%">角塊3翻I</th>      <th width="50%">角塊3翻II</th>    </tr>  </thead>  <tbody>    <tr>      <!-- <td width="50%"><img src="http://cube.rider.biz/visualcube.php?fmt=svg&size=150&pzl=3&bg=t&view=plan&fd=nuuuuunununnnnnnnnunnnnnnnndddddddddunnnnnnnnnnnnnnnnn"/></td> -->      <td width="50%"><img src="/Yang-Chinese-Blog/post/1635b73a/oll-2-1.png"/></td>      <!-- <td width="50%"><img src="http://cube.rider.biz/visualcube.php?fmt=svg&size=150&pzl=3&bg=t&view=plan&fd=uunuuununnnunnnnnnnnunnnnnndddddddddnnunnnnnnnnnnnnnnn"/></td> -->      <td width="50%"><img src="/Yang-Chinese-Blog/post/1635b73a/oll-2-2.png"/></td>    </tr>    <tr>      <td width="50%" style="text-align: center;"><strong>R U2 R' U' R U' R'</strong></td>      <td width="50%" style="text-align: center;"><strong>L' U2 L U L' U L</strong></td>    </tr>  </tbody></table><table width="100%">  <thead>    <tr>      <th width="50%">角塊4翻I</th>      <th width="50%">角塊4翻II</th>    </tr>  </thead>  <tbody>    <tr>      <!-- <td width="50%"><img src="http://cube.rider.biz/visualcube.php?fmt=svg&size=150&pzl=3&bg=t&view=plan&fd=nunuuununnnnnnnnnnununnnnnndddddddddnnnnnnnnnununnnnnn"/></td> -->      <td width="50%"><img src="/Yang-Chinese-Blog/post/1635b73a/oll-2-3.png"/></td>      <!-- <td width="50%"><img src="http://cube.rider.biz/visualcube.php?fmt=svg&size=150&pzl=3&bg=t&view=plan&fd=nunuuununnnnnnnnnnnnunnnnnndddddddddununnnnnnunnnnnnnn"/></td> -->      <td width="50%"><img src="/Yang-Chinese-Blog/post/1635b73a/oll-2-4.png"/></td>    </tr>    <tr>      <td width="50%" style="text-align: center;"><strong>F (R U R' U')3 F'</strong></td>      <td width="50%" style="text-align: center;"><strong>R U2 R2 U' R2 U' R2 U2 R</strong></td>    </tr>  </tbody></table><table width="100%">  <thead>    <tr>      <th width="33%">角塊2翻I</th>      <th width="33%">角塊2翻II</th>      <th width="33%">角塊2翻III</th>    </tr>  </thead>  <tbody>    <tr>      <!-- <td width="33%"><img src="http://cube.rider.biz/visualcube.php?fmt=svg&size=150&pzl=3&bg=t&view=plan&fd=uunuuunuunnunnnnnnunnnnnnnndddddddddnnnnnnnnnnnnnnnnnn"/></td> -->      <td width="33%"><img src="/Yang-Chinese-Blog/post/1635b73a/oll-2-5.png"/></td>      <!-- <td width="33%"><img src="http://cube.rider.biz/visualcube.php?fmt=svg&size=150&pzl=3&bg=t&view=plan&fd=nuuuuunuunnnnnnnnnunnnnnnnndddddddddnnnnnnnnnnnunnnnnn"/></td> -->      <td width="33%"><img src="/Yang-Chinese-Blog/post/1635b73a/oll-2-6.png"/></td>      <!-- <td width="33%"><img src="http://cube.rider.biz/visualcube.php?fmt=svg&size=150&pzl=3&bg=t&view=plan&fd=nunuuuuuunnnnnnnnnnnnnnnnnndddddddddnnnnnnnnnununnnnnn"/></td> -->      <td width="33%"><img src="/Yang-Chinese-Blog/post/1635b73a/oll-2-7.png"/></td>    </tr>    <tr>      <td width="33%" style="text-align: center;"><strong>L' B' R' B L B' R B</strong></td>      <td width="33%" style="text-align: center;"><strong>L' B' R B L B' R' B</strong></td>      <td width="33%" style="text-align: center;"><strong>R2 D' R U2 R' D R U2 R</strong></td>    </tr>  </tbody></table><h1 id="PLL"><a href="#PLL" class="headerlink" title="PLL"></a>PLL</h1><p>在魔術方塊的PLL (Permutation of the Last Layer)階段，我們的目標是將最後一層的方塊全部排列到正確的位置上。本篇我們會使用兩段式PLL。這個策略將最後一層的置換分為兩個階段來完成。在這種策略下，解題者會先確定最後一層所有<em><strong>角塊</strong></em>的正確位置，然後再進行<em><strong>邊塊</strong></em>的置換。</p><h2 id="PLL第一階段"><a href="#PLL第一階段" class="headerlink" title="PLL第一階段"></a>PLL第一階段</h2><p>PLL第一階段會先確定最後一層所有<em><strong>角塊</strong></em>都到正確位置。第一階段只會有兩種情況：無一側角落同色或是有一側角落同色。</p><table width="100%">  <thead>    <tr>      <th width="50%">無一側角落同色</th>      <th width="50%">有一側角落同色</th>    </tr>  </thead>  <tbody>    <tr>      <!-- <td width="50%"><img src="http://cube.rider.biz/visualcube.php?fmt=svg&size=150&pzl=3&bg=t&view=plan&fd=uuuuuuuuunnnnnnnnnnnnnnnnnndddddddddnnnnnnnnnnnnnnnnnn"/></td> -->      <td width="50%"><img src="/Yang-Chinese-Blog/post/1635b73a/pll-1-1.png"/></td>      <!-- <td width="50%"><img src="http://cube.rider.biz/visualcube.php?fmt=svg&size=150&pzl=3&bg=t&view=plan&fd=uuuuuuuuunnnnnnnnnnnnnnnnnndddddddddlnlllllllnnnnnnnnn"/></td> -->      <td width="50%"><img src="/Yang-Chinese-Blog/post/1635b73a/pll-1-2.png"/></td>    </tr>    <tr>      <td width="50%" style="text-align: center;"><strong>F R U' R' U' R U R' F' (R U R' U') (R'F R F')</strong></td>      <td width="50%" style="text-align: center;"><strong>(R U R' U') R' F R2 U' R' U' R U R' F'</strong></td>    </tr>  </tbody></table><h2 id="PLL第二階段"><a href="#PLL第二階段" class="headerlink" title="PLL第二階段"></a>PLL第二階段</h2><p>PLL第二階段會確定最後一層所有<em><strong>邊塊</strong></em>都到正確位置。</p><table width="100%">  <thead>    <tr>      <th width="50%">Ua-Perm</th>      <th width="50%">Ub-Perm</th>    </tr>  </thead>  <tbody>    <tr>      <!-- <td width="50%"><img src="http://cube.rider.biz/visualcube.php?fmt=svg&size=150&pzl=3&bg=t&view=plan&alg=M2U3MU2M3U3M2&arw=U5U3-s7,U7U5-s7,U3U7-s7"/></td> -->      <td width="50%"><img src="/Yang-Chinese-Blog/post/1635b73a/pll-ua.png"/></td>      <!-- <td width="50%"><img src="http://cube.rider.biz/visualcube.php?fmt=svg&size=150&pzl=3&bg=t&view=plan&alg=M2UMU2M3UM2&arw=U3U5-s7,U5U7-s7,U7U3-s7"/></td> -->      <td width="50%"><img src="/Yang-Chinese-Blog/post/1635b73a/pll-ub.png"/></td>    </tr>    <tr>      <td width="50%" style="text-align: center;"><strong>M2 U M U2 M' U M2</strong></td>      <td width="50%" style="text-align: center;"><strong>M2 U' M U2 M' U' M2</strong></td>    </tr>  </tbody></table><table width="100%">  <thead>    <tr>      <th width="50%">H-Perm</th>      <th width="50%">Z-Perm</th>    </tr>  </thead>  <tbody>    <tr>      <!-- <td width="50%"><img src="http://cube.rider.biz/visualcube.php?fmt=svg&size=150&pzl=3&bg=t&view=plan&alg=M2U(M2U2M2)UM2&arw=U1U7,U7U1,U3U5,U5U3"/></td> -->      <td width="50%"><img src="/Yang-Chinese-Blog/post/1635b73a/pll-h.png"/></td>      <!-- <td width="50%"><img src="http://cube.rider.biz/visualcube.php?fmt=svg&size=150&pzl=3&bg=t&view=plan&alg=M3UM2UM2UM3U2M2U&arw=U1U5,U5U1,U3U7,U7U3"/></td> -->      <td width="50%"><img src="/Yang-Chinese-Blog/post/1635b73a/pll-z.png"/></td>    </tr>    <tr>      <td width="50%" style="text-align: center;"><strong>M2 U (M2 U2 M2) U M2</strong></td>      <td width="50%" style="text-align: center;"><strong>M' U (M2 U M2 U) M' U2 M2</strong></td>    </tr>  </tbody></table><h1 id="結語"><a href="#結語" class="headerlink" title="結語"></a>結語</h1><p>練習是達到高效解題的關鍵。因為每一次的嘗試都讓我們更接近成為魔術方塊高手的目標。希望這個部落格能啟發讀者的魔術方塊探索之旅，解開更多的可能性。如果未來有更快的魔術方塊解法，我也會在此分享。</p><h1 id="References"><a href="#References" class="headerlink" title="References"></a>References</h1><ol><li><a href="https://1hrbld.tw/category/algdb/3x3-pll-algs/">https://1hrbld.tw/category/algdb/3x3-pll-algs/</a></li><li><a href="http://cube.rider.biz/visualcube.php">http://cube.rider.biz/visualcube.php</a></li><li><a href="https://chiacube.tw/Basic/Rotate">https://chiacube.tw/Basic/Rotate</a></li><li><a href="https://www.cubeskills.com/uploads/pdf/tutorials/f2l.pdf">https://www.cubeskills.com/uploads/pdf/tutorials/f2l.pdf</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> 生活 </category>
          
          <category> 娛樂 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 魔術方塊 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SVD的微分推導</title>
      <link href="/Yang-Chinese-Blog/post/b8597833.html"/>
      <url>/Yang-Chinese-Blog/post/b8597833.html</url>
      
        <content type="html"><![CDATA[<p>最近剛好做的研究題目跟SVD有關，需要把SVD應用在神經網路裡面。所以就想說手推一下SVD的導數，並把它紀錄下來，以免之後老年癡呆都忘光光。想要看懂這篇的人也要有一點心理準備，等等的數學真的很不友善，我也是花了好久的時間才整理完這篇文章。</p><h1 id="奇異值分解"><a href="#奇異值分解" class="headerlink" title="奇異值分解"></a>奇異值分解</h1><p>奇異值分解(Singular Value Decomposition, SVD)是線性代數裡邊一個重要的主題，主要就是在進行任意矩陣分解。在信號處理、圖像修復、數據壓縮、降噪、統計學有重要應用。</p><h2 id="SVD分解"><a href="#SVD分解" class="headerlink" title="SVD分解"></a>SVD分解</h2><p>設$A$為一個$m \times n$的實矩陣，且$rank(A) &#x3D; r$，則full SVD具有以下形式：</p><p>\begin{equation}<br>   A &#x3D; U \Sigma V^T<br>   \label{eq:svd}<br>\end{equation}</p><p>其中$U \in \mathbb{R}^{m \times m}$、$\Sigma \in \mathbb{R}^{m \times n}$、$V \in \mathbb{R}^{n \times n}$。方陣$U$和$V$都是實正交矩陣(orthogonal matrix)。這邊我只考慮compact SVD，也就是$A &#x3D; U_r \Sigma_r V^T_r$。現在的三個矩陣維度分別為$U \in \mathbb{R}^{m \times r}$、$\Sigma \in \mathbb{R}^{r \times r}$、$V \in \mathbb{R}^{r \times n}$。矩陣的秩(rank)代表的是對存儲在矩陣$A$中的獨特信息的量，rank越高則信息越多。</p><h2 id="SVD求導"><a href="#SVD求導" class="headerlink" title="SVD求導"></a>SVD求導</h2><p>既然我們知道了$rank(A) &#x3D; r$，則$r \leq min(m, n)$。我們還知道$U$和$V$都是實正交，則</p><p>\begin{equation}<br>    U^T U &#x3D; V^T V &#x3D; I_r<br>    \label{eq:constraint}<br>\end{equation}</p><p>現在$A$的導數可以寫成</p><p>\begin{equation}<br>   dA &#x3D; dU \Sigma V^T + U d\Sigma V^T + U \Sigma dV^T<br>   \label{eq:diff-svd}<br>\end{equation}</p><p>在限制式$\ref{eq:constraint}$中，我們可以先對$U$求導，得到</p><p>\begin{equation}<br>   dU^T U + U^T dU &#x3D; 0<br>\end{equation}</p><p>並且假設一個新的矩陣$d\Omega_U &#x3D; U^T dU$。因為$d\Omega_U &#x3D; U^T dU &#x3D; - dU^T U$，所以我們可以知道$d\Omega$是一個反對稱矩陣(skew-symmetric)。類似地，我們可以得到$d\Omega_V &#x3D; V^T dV &#x3D; - dV^T V$，所以$d\Omega_V$也是一個反對稱矩陣。</p><p>對矩陣$A$左乘$U^T$並且右乘$V$，我們可以得到</p><p>\begin{equation}<br>\begin{aligned}<br>    U^T dA V &amp;&#x3D; U^T dU \Sigma V^T V + U^T U d\Sigma V^T V + U^T U \Sigma dV^T V \\<br>             &amp;&#x3D; d\Omega_U \Sigma + d\Sigma + \Sigma d\Omega_V^T<br>\end{aligned}<br>\label{eq:diff-svd-dp}<br>\end{equation}</p><p>現在我們定義$dP \equiv U^T dA V$，且使用$X \circ Y$來表示$X$和$Y$的Hadamard product。我們現在要分別去算$dP$斜對角元素和非斜對角元素的值。首先，我們求得$dP$斜對角元素為</p><p>\begin{equation}<br>   I_r \circ dP &#x3D; d\Sigma<br>   \label{eq:diff-svd-diagonal}<br>\end{equation}</p><p>且$dP$的非斜對角元素為</p><p>\begin{equation}<br>\begin{aligned}<br>   \bar{I_r} \circ dP &amp;&#x3D; d\Omega_U \Sigma + \Sigma d\Omega_V^T \\<br>                         &amp;&#x3D; d\Omega_U \Sigma - \Sigma d\Omega_V<br>\end{aligned}<br>\label{eq:diff-svd-dp-nondiagonal}<br>\end{equation}</p><p>由此可得$dP^T$的非斜對角元素為</p><p>\begin{equation}<br>   \bar{I_r} \circ dP^T &#x3D; - \Sigma d\Omega_U + d\Omega_V \Sigma<br>   \label{eq:diff-svd-dpt-nondiagonal}<br>\end{equation}</p><p>現在我們對式子$\ref{eq:diff-svd-dp-nondiagonal}$右乘$\Sigma$，並對式子$\ref{eq:diff-svd-dpt-nondiagonal}$左乘$\Sigma$，然後做相加可得</p><p>\begin{equation}<br>\begin{aligned}<br>    \bar{I_r} \circ (dP \Sigma + \Sigma dP^T) &amp;&#x3D; (d\Omega_U \Sigma^2 + \Sigma d\Omega_V^T \Sigma) + (- \Sigma^2 d\Omega_U + \Sigma d\Omega_V \Sigma) \\<br>    &amp;&#x3D; (d\Omega_U \Sigma^2 - \Sigma^2 d\Omega_U) + (\Sigma d\Omega_V^T \Sigma + \Sigma d\Omega_V \Sigma) \\<br>    &amp;&#x3D; d\Omega_U \Sigma^2 - \Sigma^2 d\Omega_U<br>\end{aligned}<br>\end{equation}</p><p>最終可以得到</p><p>\begin{equation}<br>    d\Omega_U &#x3D; F \circ (dP \Sigma + \Sigma dP^T)<br>    \label{eq:omega-u}<br>\end{equation}</p><p>其中</p><p>\begin{equation}<br>    F &#x3D;<br>    \begin{cases}<br>      \frac{1}{\sigma_j^2 - \sigma_i^2} &amp; i \neq j \\<br>      0 &amp; i &#x3D; j<br>    \end{cases}<br>\end{equation}</p><p>藉由類似的推導，我們也可以得到</p><p>\begin{equation}<br>    d\Omega_V &#x3D; F \circ (\Sigma dP + dP^T \Sigma)<br>    \label{eq:omega-v}<br>\end{equation}</p><p>因為$d\Omega_U &#x3D; U^T dU$，所以藉由左乘$U$我們得到$dU &#x3D; U d\Omega_U$。</p><p>再繼續更深入的SVD導數推導之前，我們要先了解一些正交補餘(orthogonal complement)和投影矩陣(projection matrix)的性質。假設$U$的正交補餘矩陣為$U_{\bot}$且維度為$m \times (m-r)$，其中$U_{\bot}$可以藉由Gram-Schmidt process算出，這邊就不再詳細介紹這個算法。另外，投影矩陣$H$必須滿足$H^2 &#x3D; H$和$H^T &#x3D; H$，也就是自己的平方和自己的轉置都必須是自己。現在我們要來證明$U_{\bot} U_{\bot}^{T}$和$I - U U^{T}$都是投影矩陣。</p><p>\begin{equation}<br>    (U_{\bot} U_{\bot}^{T})^2 &#x3D; U_{\bot} (U_{\bot}^{T} U_{\bot}) U_{\bot}^{T} &#x3D; U_{\bot} U_{\bot}^{T}<br>\end{equation}</p><p>\begin{equation}<br>    (U_{\bot} U_{\bot}^{T})^T &#x3D; (U_{\bot}^{T})^T (U_{\bot})^T &#x3D; U_{\bot} U_{\bot}^{T}<br>\end{equation}</p><p>\begin{equation}<br>    (I - U U^{T})^2 &#x3D; I - 2 U U^{T} + U U^{T} U U^{T} &#x3D; I - U U^{T}<br>\end{equation}</p><p>\begin{equation}<br>    (I - U U^{T})^T &#x3D; (I - U U^{T})<br>\end{equation}</p><p>除此之外，我們還必須了解$U$和$U_{\bot}$是否可以組成整個生成空間。我們先假設這句話為真，那麼對於任何一個向量空間都必須是$U$和$U_{\bot}$的線性組合，也就是$S &#x3D; aU + bU_{\bot}$，其中$a, b$為純量、$S$為一矩陣。我們先將$S$透過投影向量$U U^T$映射到$U$的行空間：</p><p>\begin{equation}<br>    U U^T S &#x3D; U U^T (aU + bU_{\bot}) &#x3D; a U (U^T U)  + b U_{\bot} (U^T U_{\bot}) &#x3D; a U<br>\end{equation}</p><p>其中$U^T U &#x3D; I$($U$為正交矩陣)，還有$U^T U_{\bot} &#x3D; 0$(因為$U$和$U_{\bot}$正交)。類似地，我們也可以將$S$透過投影向量$U_{\bot} U_{\bot}^T$映射到$U_{\bot}$的行空間：</p><p>\begin{equation}<br>    U_{\bot} U_{\bot}^T S &#x3D; U_{\bot} U_{\bot}^T (a U + b U_{\bot}) &#x3D; a U_{\bot} (U_{\bot}^T U) + b U_{\bot} (U_{\bot}^T U_{\bot}) &#x3D; b U_{\bot}<br>\end{equation}</p><p>合在一起看的話就是：</p><p>\begin{equation}<br>\begin{aligned}<br>    (U U^T + U_{\bot} U_{\bot}^T) S &amp;&#x3D; U U^T S + U_{\bot} U_{\bot}^T S \\<br>                                    &amp;&#x3D; a U + b U_{\bot} \\<br>                                    &amp;&#x3D; I S<br>\end{aligned}<br>\end{equation}</p><p>所以，我們可以得到$U U^T + U_{\bot} U_{\bot}^T$就是一個identity matrix。我們可以寫成以下恆等式：</p><p>\begin{equation}<br>    U_{\bot} U_{\bot}^T &#x3D; I - U U^T<br>\end{equation}</p><p>回歸到SVD的求導。為了求$dA$(式子\ref{eq:diff-svd})，我們需要算出$dU$、$d\Sigma$、$dV^T$。可以想像把SVD視為一種函示映射$f$，然後對輸入矩陣$A$增加擾動$dA$。那也就相當於對生成$A$的行空間的$U$進行擾動$dU$、對生成$A$的列空間的$V$進行擾動$dV$。不失一般性的，我們先看$dU$。假設$dU$在$U$的整個行空間($m \times m$)進行擾動，其中還可以分解為在$m \times r$和$m \times (m-r)$的部分進行擾動。所以我們可以寫成以下式子：</p><p>\begin{equation}<br>    dU &#x3D; U d\Omega_U + U_{\bot} dK_U<br>    \label{eq:du}<br>\end{equation}</p><p>其中我們已經求出$d\Omega_U$(式子\ref{eq:omega-u})，現在需要去解$dK_U$。我們對$dA$左乘一個$U_{\bot}^{T}$得到：</p><p>\begin{equation}<br>\begin{aligned}<br>    U_{\bot}^{T} dA &amp;&#x3D; U_{\bot}^{T} dU \Sigma V^T + U_{\bot}^{T} U d\Sigma V^T + U_{\bot}^{T} U \Sigma dV^T \\<br>                    &amp;&#x3D; U_{\bot}^{T} dU \Sigma V^T \\<br>                    &amp;&#x3D; U_{\bot}^{T} (U d\Omega_U + U_{\bot} dK_U) \Sigma V^T \\<br>                    &amp;&#x3D; (U_{\bot}^{T} U d\Omega_U + U_{\bot}^{T} U_{\bot} dK_U) \Sigma V^T \\<br>                    &amp;&#x3D; dK_U \Sigma V^T<br>\end{aligned}<br>\label{eq:compute-dk-u}<br>\end{equation}</p><p>整理一下式子\ref{eq:compute-dk-u}就可以得到$dK_U$：</p><p>\begin{equation}<br>    dK_U &#x3D; U_{\bot}^{T} dA V \Sigma^{-1}<br>    \label{eq:dk-u}<br>\end{equation}</p><p>同理，我們可以去算$dV$</p><p>\begin{equation}<br>    dV &#x3D; V d\Omega_V + V_{\bot} dK_V<br>    \label{eq:dv}<br>\end{equation}</p><p>然後得到$dK_V$</p><p>\begin{equation}<br>    dK_V &#x3D; V_{\bot}^{T} dA^T U \Sigma^{-1}<br>    \label{eq:dk-v}<br>\end{equation}</p><p>把式子\ref{eq:omega-u}和式子\ref{eq:dk-u}代入\ref{eq:du}可以得到$dU$，把式子\ref{eq:omega-v}和式子\ref{eq:dk-v}代入\ref{eq:dv}可以得到$dV$。</p><p>\begin{equation}<br>    dU &#x3D; U (F \circ (U^T dA V \Sigma + \Sigma V^T dA^T U)) + (I_m - U U^T) dA V \Sigma^{-1}<br>\end{equation}</p><p>\begin{equation}<br>    d\Sigma &#x3D; I_r \circ (U^T dA V)<br>\end{equation}</p><p>\begin{equation}<br>    dV &#x3D; V (F \circ (\Sigma U^T dA V + V^T dA^T U \Sigma)) + (I_n - V V^T) dA^T U \Sigma^{-1}<br>\end{equation}</p><h1 id="主成分分析"><a href="#主成分分析" class="headerlink" title="主成分分析"></a>主成分分析</h1><p>在多元統計分析中，主成分分析(Principal Components Analysis, PCA)是一種統計分析和數據降維的方法。數學定義上，PCA的基本思想是使用一個正交化線性轉換把原始數據(sample matrix)轉換到一個新的座標系統上，並且投影在新的座標後仍保留數據最大的變異。換句話說，這一數據的任何投影的第一大變異數在第一個坐標上，第二大變異數在第二個坐標上，依次類推。</p><h2 id="預備知識"><a href="#預備知識" class="headerlink" title="預備知識"></a>預備知識</h2><p>首先，我們要先了解怎麼對數據做中心化(centralisation)。</p><p>\begin{equation}<br>X_{n \times d} &#x3D;<br>    \begin{pmatrix}<br>            x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1d} \\<br>            x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2d} \\<br>            \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\<br>            x_{n1} &amp; x_{n2} &amp; \cdots &amp; x_{nd}<br>    \end{pmatrix}<br>\end{equation}</p><p>\begin{equation}<br>\mu_{d \times 1} &#x3D;<br>    \begin{pmatrix}<br>            \frac{1}{n} \sum\limits_{i&#x3D;1}^{n} x_{i1} \\<br>            \vdots \\<br>            \frac{1}{n} \sum\limits_{i&#x3D;1}^{n} x_{in}<br>    \end{pmatrix}<br>\end{equation}</p><p>對每一行操作特徵零均值化：</p><p>\begin{equation}<br>\begin{aligned}<br>\tilde{X}<br>    &amp;&#x3D; X - \mathbb{1}_{n \times 1} \mu^T \\<br>    &amp;&#x3D; \begin{pmatrix} x_1 &amp; \cdots &amp; x_d \end{pmatrix} - \begin{pmatrix} \frac{1}{n} \sum\limits_{i&#x3D;1}^{n} x_{i1} &amp; \cdots &amp; \frac{1}{n} \sum\limits_{i&#x3D;1}^{n} x_{id} \end{pmatrix} \\<br>    &amp;&#x3D; \begin{pmatrix}<br>            x_{11} - \frac{1}{n} \sum\limits_{i&#x3D;1}^{n} x_{i1} &amp; \cdots &amp; x_{1d} - \frac{1}{n} \sum\limits_{i&#x3D;1}^{n} x_{id} \\<br>            \vdots &amp; \ddots &amp; \vdots \\<br>            x_{n1} - \frac{1}{n} \sum\limits_{i&#x3D;1}^{n} x_{i1} &amp; \cdots &amp; x_{nd} - \frac{1}{n} \sum\limits_{i&#x3D;1}^{n} x_{id}<br>        \end{pmatrix} \\<br>    &amp;&#x3D; \begin{pmatrix}<br>            (1 - \frac{1}{n}) x_{11} - \cdots - \frac{1}{n} x_{n1} &amp; \cdots &amp; (1 - \frac{1}{n}) x_{1d} - \cdots - \frac{1}{n} x_{nd} \\<br>            \vdots &amp; \ddots &amp; \vdots \\<br>            - \frac{1}{n} x_{11} - \cdots + (1 - \frac{1}{n}) x_{n1} &amp; \cdots &amp; - \frac{1}{n} x_{1d} - \cdots + (1 - \frac{1}{n}) x_{nd}<br>        \end{pmatrix} \\<br>    &amp;&#x3D; \begin{pmatrix}<br>            1 - \frac{1}{n} &amp; - \frac{1}{n} &amp; \cdots &amp; - \frac{1}{n} \\<br>            - \frac{1}{n} &amp; 1 - \frac{1}{n} &amp; \cdots &amp; - \frac{1}{n} \\<br>            \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\<br>            - \frac{1}{n} &amp; - \frac{1}{n} &amp; \cdots &amp; 1 - \frac{1}{n}<br>        \end{pmatrix} \cdot \begin{pmatrix} x_1 &amp; \cdots &amp; x_d \end{pmatrix} \\<br>    &amp;&#x3D; (I_n - \frac{1}{n} \mathbb{1}_{n \times n}) \cdot X_{n \times d} \\<br>    &amp;&#x3D; \tilde{I}_{n \times n} \cdot X_{n \times d}<br>\end{aligned}<br>\end{equation}</p><p>其中<a href="https://en.wikipedia.org/wiki/Centering_matrix">居中矩陣</a>(centering matrix)是一個正交投影矩陣(orthogonal projection matrix)滿足：</p><p>\begin{equation}<br>    \tilde{I} &#x3D; \tilde{I}^2 &#x3D; \tilde{I}^T<br>\end{equation}</p><p>第二個要會的是算一下斜方差矩陣(sample covariance matrix)。</p><p>\begin{equation}<br>\begin{aligned}<br>    C &amp;&#x3D; \frac{1}{n} \sum_{i&#x3D;1}^{n} (x_i - \mu) (x_i - \mu)^T \\<br>      &amp;&#x3D; \frac{1}{n} \tilde{X}^T \tilde{X} \\<br>      &amp;&#x3D; \frac{1}{n} (\tilde{I} X)^T (\tilde{I} X) \\<br>      &amp;&#x3D; \frac{1}{n} X^T \tilde{I}^T \tilde{I} X \\<br>      &amp;&#x3D; \frac{1}{n} X^T \tilde{I} X<br>\end{aligned}<br>\end{equation}</p><h2 id="PCA思想"><a href="#PCA思想" class="headerlink" title="PCA思想"></a>PCA思想</h2><p>假如原始的樣本$X \in \mathbb{R}^{n \times d}$($n$個數據點且特徵維度是$d$)。單看其中一筆數據$x_i$在座標$v \in \mathbb{R}^{d}$上做投影，則會得到</p><p>\begin{equation}<br>    proj_{v} x_i &#x3D; \frac{v^{T} x_{i}}{\lVert v \rVert^2} v<br>\end{equation}</p><p>不失一般性，我們假設$v$是單位向量，則可以得到投影後的數據點是$(v^T x_i) v$。那麼我們可以得到去中心化後的數據的方差為：</p><p>\begin{equation}<br>\begin{aligned}<br>    \frac{1}{n} \sum_{i&#x3D;1}^{n} (\tilde{x}_i^T v - 0)^2<br>        &amp;&#x3D; \frac{1}{n} \sum_{i&#x3D;1}^{n} (\tilde{x}_i^T v)^T (\tilde{x}_i^T v) \\<br>        &amp;&#x3D; \frac{1}{n} \sum_{i&#x3D;1}^{n} v^T \tilde{x}_i \tilde{x}_i^T v \\<br>        &amp;&#x3D; v^T (\frac{1}{n} \sum_{i&#x3D;1}^{n} \tilde{x}_i \tilde{x}_i^T) v \\<br>        &amp;&#x3D; v^T (\frac{1}{n} \tilde{X}^T \tilde{X}) v \\<br>        &amp;&#x3D; v^T C v<br>\end{aligned}<br>\end{equation}</p><p>我們希望可以最大化投影後的數據方差，則可以利用拉格朗日函數建立目標函數：</p><p>\begin{equation}<br>    \mathcal{L}(v) &#x3D; - v^T C v + \lambda (v^T v - 1)<br>\end{equation}</p><p>對$v$求導可以得到：</p><p>\begin{equation}<br>    \frac{\partial \mathcal{L}}{\partial v} &#x3D; -2 C v + 2 \lambda v &#x3D; 0<br>\end{equation}</p><p>最終得到：</p><p>\begin{equation}<br>    C v &#x3D; \lambda v<br>\end{equation}</p><p>所以，我們可以得到$v$是$C$的特徵向量，$\lambda$是對應的特徵向量的特徵值。要是想要最大化$v^T C v$，那就必須要最大化$\lambda$，因為$v^T C v &#x3D; v^T \lambda v &#x3D; \lambda v^T v &#x3D; \lambda$。</p><p>這裡還需要證明一下另外一個重要的性質。對於$X$的第$j$個主要成分$v_{j}$會是斜方差矩陣$C$第$j$大的特徵向量，對應的$\lambda_{j}$是第$j$大的特徵值。這邊會證明$j&#x3D;2$的例子：</p><p>\begin{equation}<br>    v_2 &#x3D; \underset{\lVert v \rVert^2 &#x3D; 1, v_1^T v &#x3D; 0}{\operatorname{arg max}} v^T C v<br>\end{equation}</p><p>一樣列出拉格朗日函數的目標函數</p><p>\begin{equation}<br>    \mathcal{L}(v) &#x3D; - v^T C v + \alpha_1 (v^T v - 1) + \alpha_2 (v_{1}^{T} v)<br>\end{equation}</p><p>最小化$\mathcal{L}(v)$可以得到</p><p>\begin{equation}<br>    -2 C v + 2 \alpha_1 v + \alpha_2 v_1 &#x3D; 0<br>\end{equation}</p><p>所以$\alpha_2 &#x3D; 0$且$C v &#x3D; \alpha_1 v$。想要最大化$v^T C v$的話，$v_2$就必須是第二大的特徵向量且$\alpha_1 &#x3D; \lambda_2$。</p><h1 id="總結"><a href="#總結" class="headerlink" title="總結"></a>總結</h1><p>首先我要恭喜有成功看完這篇文章並且沒有腦死的各位。<br>之後我投的paper有成功上岸，我會再寫一篇文章來分享。</p><h1 id="References"><a href="#References" class="headerlink" title="References"></a>References</h1><ol><li>Edelman et al., The geometry of algorithms with orthogonality constraints, 1998</li><li>Townsend, Differentiating the singular value decomposition, 2016</li><li>Wang et al., Robust Differentiable SVD, 2021</li></ol>]]></content>
      
      
      <categories>
          
          <category> 科研 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SVD </tag>
            
            <tag> 矩陣分解 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>英國Research Intern的經歷</title>
      <link href="/Yang-Chinese-Blog/post/a949fbb9.html"/>
      <url>/Yang-Chinese-Blog/post/a949fbb9.html</url>
      
        <content type="html"><![CDATA[<p>這邊來稍微紀錄一下我在英國實習的經過。想當初從Google上面搜尋別人分享的海外實習經歷，都只能跳出一些留學仲介發的廣告文，或是那種求職網站給的JD(job describtion)。我就想說我要分享給其他有需要的人們，或許某些正在英國找實習的人可以從中找到啟發。</p><h1 id="VoiceBase-Centre"><a href="#VoiceBase-Centre" class="headerlink" title="VoiceBase Centre"></a>VoiceBase Centre</h1><p>在英國讀碩士的期間，我做了兩份實習。</p><p>第一份實習，算是非常非常的幸運，可以說是被我撿到的。</p><h2 id="運氣爆棚"><a href="#運氣爆棚" class="headerlink" title="運氣爆棚"></a>運氣爆棚</h2><p>剛開學那時候，整個學院大概有200位學生要準備去搶碩士題目。但是我對大部分的題目都是興致缺缺。所以我就選擇自己寫了一份research proposal，貼在學校的網站布告欄上，希望有教授對我的topic感興趣。我給大約20位教授發了信，跟他們自薦了一番，希望我可以成為他們的指導學生。不過到最後，只有三位教授給我回了信。</p><p>大約過了一周，SpandH組的Thomas Hain教授也給我發了封信。他說非常抱歉沒有在選題目的deadline之前給我回信，因為他人不舒服無法給我回應(我猜應該是covid)。Thomas跟我說他實驗室有研究實習的缺，問我有沒有興趣。我當時高興到飛天，馬上就給了他一個正面回應。</p><h2 id="語音識別面試"><a href="#語音識別面試" class="headerlink" title="語音識別面試"></a>語音識別面試</h2><p>過了兩三天，Thomas就說想跟我面試一下，看一下我的research ability。在面試的過程中，Mauro Nicolao和‪Md Asif Jalal‬(未來的兩位internship supervisors)也在場跟Thomas一起面試我。基本上就是一些motivations和數學相關的問題。也問了一些當時碩士課程裡面的語音相關問題，還有對深度學習神經網路的理解程度。我把當時被問的題目整理成下面的bullet points：</p><ul><li>Describe an important project you’ve worked on.</li><li>Have you ever worked on a project related to speech?</li><li>Why is it possible to use matrix decomposition to speed up the neural networks?</li><li>What else you can apply to with the help of matrix decomposition technique?</li><li>Do you know how to use speech recognition tools like HTK or Kaldi?</li></ul><p>過沒多久，我就收到了offer，也得知了要在裡面做什麼樣的project。這是有關於robust channel demixing的語音任務。如果之後有人有興趣，我也會對此單獨發一篇文來分享一下。</p><p>我知道這份實習的前半部分一定會很煎熬，畢竟當時還有60學分要努力，還得每周固定跟Thomas報告我項目的進度。我還要摸熟很多我根本就沒碰過的技術，包含HPC (high performance computing)、mini-framework、linux等等。我那時也對語音領域一竅不通，也就是剛學會一些filter bank、MFCC之類的鬼東西的程度。但隨著課程的跟進和我對這些frameworks的熟悉後，我也就開始漸入佳境。</p><h1 id="eSalesHub"><a href="#eSalesHub" class="headerlink" title="eSalesHub"></a>eSalesHub</h1><p>另外一份實習，我只能說是用我之前的努力換來的回報。</p><h2 id="碩論空窗期"><a href="#碩論空窗期" class="headerlink" title="碩論空窗期"></a>碩論空窗期</h2><p>快要畢業的時候，我的指導教授Chenghua Lin對我的碩士論文挺滿意的，所以就推薦我去一間在Doncaster的公司eSalesHub做research intern。這是一間很local的英國新創。我進去的時候公司可能才創立不到半年吧。</p><p>我在那邊的主要任務就是要把machine learning導入到公司的產品生態裡面。希望可以讓公司透過一系列的machine learning算法來提升企業獲利。</p><h2 id="ML不是萬能"><a href="#ML不是萬能" class="headerlink" title="ML不是萬能"></a>ML不是萬能</h2><p>老實說，像eSalesHub這樣的新創公司有很多data相關規範，以及如何處理data的pipelines都不成熟。<strong>很多老闆都以為買台電腦，明天就可以把事情解決。</strong></p><p>我認為只有老闆懂了甚麼是AI、cloud technique、machine learning，才有可能讓技術真正落地。再來如果企業思維跟文化跟不上(例如跨部門整合)，說再多也只是徒勞。</p><h2 id="ML業務"><a href="#ML業務" class="headerlink" title="ML業務"></a>ML業務</h2><p>我在這個項目裡面負責的產品是Intent Classification in Call Centre。簡單來說，就是要把call centre接到的所有雙聲道phone calls做分類。我當時拿到的data是經過AWS轉換過後的transcription而非原始的audio data，所以我只能把它當作一個文字分類的任務來做。我的solution是把agent和customer的文字分別做encoder，再把他們的representations做fusion後丟進一個LightGBM分類器去做訓練。假如有人敲碗想知道細節的話，我之後會再發一篇來分享。</p><h2 id="實習小插曲"><a href="#實習小插曲" class="headerlink" title="實習小插曲"></a>實習小插曲</h2><p>我拿到的dataset非常的支離破碎。轉換成文字後，裡面的斷句(tokenisation)很多都是錯的，甚至ASR的結果也不正確，然後還有一堆filling words。這對於我要做一個text classifier是極度的不友善。我跟老闆還有工程團隊反應過後也沒有任何幫助或是回應。就連我希望可以拿到更多的data samples也是經過好幾個月才拿到一個不完整的。到後來因為老闆覺得維運困難，就把這個項目shutdown了。</p><p>在此奉勸想要去新創做machine learning的人，要記得在面試的時候就先問清楚裡面團隊對於data運作處理的方式，以及遇到各種情境的應對方式。不然就會落得跟我一樣的下場。</p><h1 id="結語"><a href="#結語" class="headerlink" title="結語"></a>結語</h1><p>總之，在英國的一年半裡，我過得還滿充實的。每天都是10小時以上的coding，除了睡覺吃飯以外都是在敲代碼。實習算是海龜生活的過客而已，但也因此認識了很多大佬研究員。總覺得這樣特別的經歷以後應該也很難會有了。</p>]]></content>
      
      
      <categories>
          
          <category> 生活 </category>
          
          <category> 留學 </category>
          
          <category> 工作 </category>
          
          <category> 實習 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 英國 </tag>
            
            <tag> 實習 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>踏上征途</title>
      <link href="/Yang-Chinese-Blog/post/5fec1f59.html"/>
      <url>/Yang-Chinese-Blog/post/5fec1f59.html</url>
      
        <content type="html"><![CDATA[<p>我們通常不清楚未來想要做什麼，這很大程度上是因為未來似乎太遙遠、太不可預測。未來會發生什麼事，我們的興趣和需求又會變成什麼樣，這些都是難以捉摸的未知數。我也不例外。大學畢業時，我陷入了迷茫，只知道自己不想從事什麼工作，卻苦無明確的職業志向。透過這篇文章，我想要紀錄未來幾年的成長與變化，希望不僅自我改變，也能啟發或影響他人的生活。</p><h1 id="在數學系的生活"><a href="#在數學系的生活" class="headerlink" title="在數學系的生活"></a>在數學系的生活</h1><p>在大學期間，我選修的課程要麼是那種大家都討厭的抽象數學，要麼是令人摸不著頭腦的邏輯推導。然而，與大家想象的乏味數學生活不同，由於我的自閉性格xD，我發現在追求解題過程中感受到極大的刺激。尤其是在那些超過90%的學生會被當掉的科目（如代數或高等微積分）中，能夠成功通過讓我體會到一種在其他學科無法經歷的成就感。</p><p>畢業後的幾個月，我感到自己像是一無是處。曾經考慮報考台清交的研究所來挽救頹勢，但回想起我那些不堪回首的考試經歷 —— 免試錄取備取落榜、基測差一分未能成功、學測體育資優考試獨占鰲頭卻仍落榜、多益考試答錯高達一百題 —— 我立刻打消了這個念頭，決定不再自討苦吃。</p><h1 id="在KKBOX的生活"><a href="#在KKBOX的生活" class="headerlink" title="在KKBOX的生活"></a>在KKBOX的生活</h1><p>我記得當初在104求職網站海投了約100家公司，大部分公司對一個像我這樣一無所長的菜鳥毫無興趣，唯獨KKBOX給了我機會。面試的經過至今仍歷歷在目，我覺得非常值得分享。</p><p>我申請的職位是Software Quality Assurance Assistant (SQA) Engineer。面試過程中，面試官提問了許多關於CI&#x2F;CD、單元測試等技術問題。每當這樣的問題出現，我的回答都出奇地一致：“我不會。”我能想像面試官當時的表情，一定覺得我非常無厘頭。面試中不僅有技術問題，還包括了行為面試題，比如朋友怎麼描述我，以及我如何處理困難等。面試的最後一個問題是關於我是否會繪製流程圖。我的回答依然是“我不會”。但面試官十分友善地提出，如果他教我流程圖的知識，我是否能繪出一個登錄系統的流程圖。我心虛地答應了，手抖著畫出了他要求的社群網站登錄系統流程圖。幸運的是，我沒有在那裡出糗。</p><p>兩週後，我收到了KKBOX的工作邀請。這真是既驚喜又激動，或許KKBOX看中了我的潛力。懷著學習和面對挑戰的心態，我打包行李，孤身一人北上開始了新生活。</p><h1 id="攻讀碩士學位的契機"><a href="#攻讀碩士學位的契機" class="headerlink" title="攻讀碩士學位的契機"></a>攻讀碩士學位的契機</h1><p>在KKBOX的日子不多，我就開始感到QA的工作實在太過單調乏味，缺乏挑戰性（希望我的前主管不會看到這句話xD）。每日重複的測試案例和源源不絕的免費下午茶及零食，讓我的大腦和體重都面臨嚴重的“轟炸”。就在某個上班時間，我偷偷在網上尋找新的領域，希望能找到轉換跑道的機會。當我無意間發現自然語言處理（NLP）這個領域時，我被其魅力深深吸引，恰巧我也很喜歡的一所學校開設了相關課程。</p><p>我沒有猶豫，立即給在NAIST的Satoshi Nakamura教授發了一封電子郵件，詢問他是否願意收我為學生。令人難以置信的是，Satoshi Nakamura教授很快就回覆了我的郵件！我當時激動得立刻跑到自動販賣機買了幾瓶養樂多來慶祝！不過教授告訴我他下周將前往德國參加一個NLP會議，要三周後才能回日本。我則是迅速回信說我會在後天親自去找他討論。</p><p>發完郵件後，我立即向主管請了假，並訂了兩天後前往日本的機票。現在想起來，那真是一時衝動的決定。</p><p>到達偏僻的奈良之後，我一度找不到學校的位置，幸虧當地的日本人非常友好，熱心指路。當我終於來到Satoshi Nakamura教授的研究室，只見那裡充滿了濃厚的學術氛圍，讓我對未來的研究生活充滿了憧憬。</p><img src="/Yang-Chinese-Blog/post/5fec1f59/naist-lab.jpg" width="50%"><p>我與Satoshi Nakamura教授的對話過程非常愉快，我們主要討論了我在數學系的學習經歷以及目前的工作情況。出乎意料的是，話題竟然轉向了台灣的鳳梨酥，這讓整個交談充滿了輕鬆的氣氛。最終，Nakamura教授也同意為我撰寫接受函，但我仍需要參加兩個月後的入學考試。</p><p>考試涵蓋了筆試和面試兩部分。筆試部分包括微積分、微分方程和線性代數，而面試則著重於我的研究計畫。回到台灣後，我開始了嚴格的準備，每天工作結束後便投入到數學學習中，一直持續到深夜十二點，這樣的日程持續了整整兩個月，期間毫無例外。</p><h2 id="NAIST入學考試"><a href="#NAIST入學考試" class="headerlink" title="NAIST入學考試"></a>NAIST入學考試</h2><p>筆試的內容涉及四題題目：兩題微分方程和兩題線性代數。我需要在這些題目中挑選一題微分方程和一題線性代數，然後在兩位教授面前使用白板進行解答。考試結束時，我對自己能夠獲得高分頗有信心，因為兩道題目我都成功解答了。</p><p>筆試結束後，我立刻進入另一間房間準備面試。面試開始前，我進行了三分鐘的自我介紹，隨後進入了關於研究計畫的詳細提問階段。以下是我當時面對的幾個問題：</p><ol><li>Please briefly explain your research proposal.</li><li>Have you done reading lots of papers regarding to your area of specialisation?</li><li>How to utilise the mentioned model (BERT and XLNet) into your research proposal?</li><li>What else could you improve on your proposed model?</li><li>Why could mathematics profession be your strength?</li><li>What is the connection between question-answering system and your research proposal?</li><li>Could you implement your chat-bot with the state-of-the-art right now?</li></ol><p>大部分問題我回答得相當有把握。只要熟讀過BERT和當時流行的XLNet的相關文獻，基本上不會遇到太大問題。最後一個問題讓我感到害怕，擔心考官會要求我當場寫代碼，因此我只好回答說做不到。當時的考官（一位日本人和一位印度人）還開玩笑說數學系的學生通常不擅長編程，我差點氣得拳頭緊握。</p><p>兩周後，考試結果公布，我未達及格分數，遺憾落榜。在那一刻，我決定向主管提出辭職，並下定決心必須考上一所國外研究所。正是在這個時候，我開始考慮前往英國攻讀NLP。</p><h2 id="英國碩士"><a href="#英國碩士" class="headerlink" title="英國碩士"></a>英國碩士</h2><p>辭職後，我就回到台中專心準備申請英國碩士的材料。我總共申請了11個Programmes。</p><ol><li>University of Nottingham, Machine Learning in Science</li><li>University of Nottingham, Data Science</li><li>University of Sheffield, Computer Science with Speech and Language Processing</li><li>University of Sheffield, Data Analytics</li><li>University of Warwick, Computer Science</li><li>University of Birmingham, Computer Science</li><li>University of Aston, Data Analytics</li><li>University of Essex, Big Data and Text Analytics</li><li>University of Essex, Data Science</li><li>University of Leicester, Data Analysis for Business Intelligence</li><li>University of Swansea, Data Science</li></ol><p>在這些申請中，六所屬於全球百大大學。不幸的是，我在一個月內就收到了四封拒絕信，這讓我將所有的希望都寄托在了雪菲爾大學上。原本以為希望渺茫，卻意外地在12月17日的下午收到了雪菲爾的有條件錄取通知！這份錄取通知的條件是我必須在雅思考試中達到6.5分，方可轉為無條件錄取。我迅速報名了兩周後的雅思考試，滿懷信心地準備迎戰。</p><p>然而，每當我需要準備重要考試時，總是會發生一些意外。報名考試的隔天，我不幸感染了流感，病倒了一整周，這真讓人措手不及。到了考試當天，我一直咳嗽不止，對此對其他考生表示深深的歉意。在這種狀況下參加考試，無疑是一場艱難的挑戰。</p><img src="/Yang-Chinese-Blog/post/5fec1f59/offer.jpg" width="50%"><p>非常慶幸最後也很狗屎運的拿到6.5低空飛過，也順利拿到unconditional offer。</p><h1 id="前往英國的準備"><a href="#前往英國的準備" class="headerlink" title="前往英國的準備"></a>前往英國的準備</h1><p>整個前往英國的經歷真的是一波三折，遇到了各種挑戰和困難。為了確保我能在英國立足，我進行了全面的準備。這包括深入了解英國文化，以及碩士課程的詳細授課大綱，我都事先做了充分的研究。在出發前，我甚至已經預習了將要學習的120學分課程，並且也大致規劃了我的碩士論文主題。我深怕自己在學習期間不堪重負，因此做了充足的準備。</p><p>另一方面，雖然獨自一人前往國外求學需要極大的勇氣，但更重要的是，這次經歷是否能讓我透過不同的教育制度學習到新的思考模式並提升我的表達能力。走出舒適區，面對文化衝擊，無疑會拓展我的國際視野。</p><p>最終，我希望所有準備前往英國的學生都能保持健康，並順利獲得他們夢寐以求的offer。也祝我自己在英國一切順利，好運連連！</p>]]></content>
      
      
      <categories>
          
          <category> 生活 </category>
          
          <category> 求學 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 日本 </tag>
            
            <tag> 英國 </tag>
            
            <tag> KKBOX </tag>
            
            <tag> 數學系 </tag>
            
            <tag> NAIST </tag>
            
            <tag> 碩士 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>

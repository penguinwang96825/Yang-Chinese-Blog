<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>魔術方塊LBL解法</title>
      <link href="/Yang-Chinese-Blog/post/1635b73a.html"/>
      <url>/Yang-Chinese-Blog/post/1635b73a.html</url>
      
        <content type="html"><![CDATA[<p>魔術方塊，這個1974年由Ernő Rubik所發明的智力遊戲，迄今仍吸引著全球數百萬愛好者。解開魔術方塊的過程不僅能增強記憶與解決問題的能力，還能帶來極大的樂趣和成就感。因此，我決定撰寫這個部落格來分享我解魔術方塊的心得與技巧，希望能幫助初學者輕鬆入門，並為那些尋求提高解題速度的人提供策略。</p><h1 id="國際轉動代號"><a href="#國際轉動代號" class="headerlink" title="國際轉動代號"></a>國際轉動代號</h1><p>轉動代號在魔術方塊社群中起著一種普遍語言的作用，全球的玩家都使用這些代號來溝通解題的步驟和方法，甚至在比賽中也以這種代號來出題！因此，當我們希望進一步提升自己的技能和實力時，學會這些轉動代號變得極其關鍵，因為只有理解這些代號，我們才能夠明白其他玩家分享的解題公式應如何操作。</p><h2 id="外層轉動符號"><a href="#外層轉動符號" class="headerlink" title="外層轉動符號"></a>外層轉動符號</h2><table>    <thead>        <tr>        <th>轉動代號</th>        <th>圖例</th>        <th>轉動代號</th>        <th>圖例</th>        </tr>    </thead>    <tbody>        <tr>        <td class="align-middle text-center" style="text-align: center;">R <span class="text-muted small">(Right)</span></td>        <td><img src="https://chiacube.tw/images/Rotate/rotate_R.svg" alt="Rotate_R" style="width: 100px; height: 100px; min-width:80px; max-width: 100%"></td>        <td class="align-middle text-center" style="text-align: center;">R'</td>        <td><img src="https://chiacube.tw/images/Rotate/rotate_R'.svg" alt="Rotate_R" style="width: 100px; height: 100px; min-width:80px; max-width: 100%"></td>        </tr>        <tr>        <td class="align-middle text-center" style="text-align: center;">U <span class="text-muted small">(Up)</span></td>        <td><img src="https://chiacube.tw/images/Rotate/rotate_U.svg" alt="Rotate_R" style="width: 100px; height: 100px; max-width: 100%"></td>        <td class="align-middle text-center" style="text-align: center;">U'</td>        <td><img src="https://chiacube.tw/images/Rotate/rotate_U'.svg" alt="Rotate_R" style="width: 100px; height: 100px; max-width: 100%"></td>        </tr>        <tr>        <td class="align-middle text-center" style="text-align: center;">F <span class="text-muted small">(Front)</span></td>        <td><img src="https://chiacube.tw/images/Rotate/rotate_F.svg" alt="Rotate_R" style="width: 100px; height: 100px; max-width: 100%"></td>        <td class="align-middle text-center" style="text-align: center;">F'</td>        <td><img src="https://chiacube.tw/images/Rotate/rotate_F'.svg" alt="Rotate_R" style="width: 100px; height: 100px; max-width: 100%"></td>        </tr>        <tr>        <td class="align-middle text-center" style="text-align: center;">L <span class="text-muted small">(Left)</span></td>        <td><img src="https://chiacube.tw/images/Rotate/rotate_L.svg" alt="Rotate_R" style="width: 100px; height: 100px; max-width: 100%"></td>        <td class="align-middle text-center" style="text-align: center;">L'</td>        <td><img src="https://chiacube.tw/images/Rotate/rotate_L'.svg" alt="Rotate_R" style="width: 100px; height: 100px; max-width: 100%"></td>        </tr>        <tr>        <td class="align-middle text-center" style="text-align: center;">D <span class="text-muted small">(Down)</span></td>        <td><img src="https://chiacube.tw/images/Rotate/rotate_D.svg" alt="Rotate_R" style="width: 100px; height: 100px; max-width: 100%"></td>        <td class="align-middle text-center" style="text-align: center;">D'</td>        <td><img src="https://chiacube.tw/images/Rotate/rotate_D'.svg" alt="Rotate_R" style="width: 100px; height: 100px; max-width: 100%"></td>        </tr>        <tr>        <td class="align-middle text-center" style="text-align: center;">B <span class="text-muted small">(Back)</span></td>        <td><img src="https://chiacube.tw/images/Rotate/rotate_B.svg" alt="Rotate_R" style="width: 100px; height: 100px; max-width: 100%"></td>        <td class="align-middle text-center" style="text-align: center;">B'</td>        <td><img src="https://chiacube.tw/images/Rotate/rotate_B'.svg" alt="Rotate_R" style="width: 100px; height: 100px; max-width: 100%"></td>        </tr>    </tbody></table><p>除此之外，為了明確的表示更多的方向與動作，在這些英文的符號後面會出現三種情況：</p><ul><li>‘：代表為動作符號逆時針旋轉。例如：R’</li><li>2：代表所指的這個動作要旋轉180度，即轉動兩步(次)。例如：R2</li><li>w：代表所指的這個動作，一次要轉動兩層。例如：Rw</li></ul><h2 id="整顆旋轉代號"><a href="#整顆旋轉代號" class="headerlink" title="整顆旋轉代號"></a>整顆旋轉代號</h2><table class="table table-bordered bg-BgGray text-center text-nowrap">    <thead>        <tr>        <th>轉動代號</th>        <th>圖例</th>        <th>轉動代號</th>        <th>圖例</th>        </tr>    </thead>    <tbody>        <tr>        <td class="align-middle" style="text-align: center;">x</td>        <td><img src="https://chiacube.tw/images/Rotate/rotate_x.svg" alt="Rotate_x" style="width: 100px; height: 100px; min-width:80px; max-width: 100%"></td>        <td class="align-middle" style="text-align: center;">x'</td>        <td><img src="https://chiacube.tw/images/Rotate/rotate_x'.svg" alt="Rotate_x'" style="width: 100px; height: 100px; min-width:80px; max-width: 100%"></td>          </tr>        <tr>        <td class="align-middle" style="text-align: center;">y</td>        <td><img src="https://chiacube.tw/images/Rotate/rotate_y.svg" alt="Rotate_y" style="width: 100px; height: 100px; min-width:80px; max-width: 100%"></td>        <td class="align-middle" style="text-align: center;">y'</td>        <td><img src="https://chiacube.tw/images/Rotate/rotate_y'.svg" alt="Rotate_y'" style="width: 100px; height: 100px; min-width:80px; max-width: 100%"></td>        </tr>        <tr>        <td class="align-middle" style="text-align: center;">z</td>        <td><img src="https://chiacube.tw/images/Rotate/rotate_z.svg" alt="Rotate_z" style="width: 100px; height: 100px; min-width:80px; max-width: 100%"></td>        <td class="align-middle" style="text-align: center;">z'</td>        <td><img src="https://chiacube.tw/images/Rotate/rotate_z'.svg" alt="Rotate_z'" style="width: 100px; height: 100px; min-width:80px; max-width: 100%"></td>        </tr>    </tbody></table><h2 id="中層轉動代號"><a href="#中層轉動代號" class="headerlink" title="中層轉動代號"></a>中層轉動代號</h2><table class="table table-bordered bg-BgGray text-center text-nowrap">    <thead>        <tr>            <th>轉動代號</th>            <th>圖例</th>            <th>轉動代號</th>            <th>圖例</th>        </tr>    </thead>    <tbody>        <tr>            <td class="align-middle" style="text-align: center;">M</td>            <td><img src="https://chiacube.tw/images/Rotate/rotate_M.svg" alt="Rotate_M" style="width: 100px; height: 100px; min-width:80px; max-width: 100%"></td>            <td class="align-middle" style="text-align: center;">M'</td>            <td><img src="https://chiacube.tw/images/Rotate/rotate_M'.svg" alt="Rotate_M'" style="width: 100px; height: 100px; min-width:80px; max-width: 100%"></td>        </tr>        <tr>            <td class="align-middle" style="text-align: center;">E</td>            <td><img src="https://chiacube.tw/images/Rotate/rotate_E.svg" alt="Rotate_E" style="width: 100px; height: 100px; min-width:80px; max-width: 100%"></td>            <td class="align-middle" style="text-align: center;">E'</td>            <td><img src="https://chiacube.tw/images/Rotate/rotate_E'.svg" alt="Rotate_E'" style="width: 100px; height: 100px; min-width:80px; max-width: 100%"></td>        </tr>        <tr>            <td class="align-middle" style="text-align: center;">S</td>            <td><img src="https://chiacube.tw/images/Rotate/rotate_S.svg" alt="Rotate_S" style="width: 100px; height: 100px; min-width:80px; max-width: 100%"></td>            <td class="align-middle" style="text-align: center;">S'</td>            <td><img src="https://chiacube.tw/images/Rotate/rotate_S'.svg" alt="Rotate_S'" style="width: 100px; height: 100px; min-width:80px; max-width: 100%"></td>        </tr>    </tbody></table><h1 id="LBL"><a href="#LBL" class="headerlink" title="LBL"></a>LBL</h1><p>LBL (Layer-By-Layer)解法是解魔術方塊中最基本也是最適合初學者學習的一種方法。這種方法按照層次逐層解開魔術方塊，讓解題者能夠較容易地理解和記憶所需的算法。步驟大致區分如下：</p><ol><li>第一層</li><li>第二層</li><li>第三層十字</li><li>第三層頂面</li><li>頂層角塊</li><li>頂層邊塊</li></ol><p>這邊我們會直接略過第一層，然後從第二層的公式開始教起。</p><h1 id="第二層"><a href="#第二層" class="headerlink" title="第二層"></a>第二層</h1><table width="100%">  <thead>    <tr>      <th width="33%">I</th>      <th width="33%">II</th>      <th width="33%">III</th>    </tr>  </thead>  <tbody>    <tr>      <!-- <td width="33%"><img src="http://cube.rider.biz/visualcube.php?fmt=svg&size=150&pzl=3&fc=nnnnnnnrnnnnnrnrrrnbnnbnbbbwwwwwwwwwoooooooooggggggggg"/></td> -->      <td width="33%"><img src="/Yang-Chinese-Blog/post/1635b73a/1.png"/></td>      <!-- <td width="33%"><img src="http://cube.rider.biz/visualcube.php?fmt=svg&size=150&pzl=3&fc=nnnnnbnnnnrnnrnrrrnnnnbnbbbwwwwwwwwwoooooooooggggggggg"/></td> -->      <td width="33%"><img src="/Yang-Chinese-Blog/post/1635b73a/2.png"/></td>      <!-- <td width="33%"><img src="http://cube.rider.biz/visualcube.php?fmt=svg&size=150&pzl=3&fc=nnnnnnnnnnnnbrnrrrnnnnbrbbbwwwwwwwwwoooooooooggggggggg"/></td> -->      <td width="33%"><img src="/Yang-Chinese-Blog/post/1635b73a/3.png"/></td>    </tr>    <tr>      <td width="33%" style="text-align: center;"><strong>F U F U F U' F' U' F'</strong></td>      <td width="33%" style="text-align: center;"><strong>R' U' R' U' R' U R U R</strong></td>      <td width="33%" style="text-align: center;"><strong>(R U U R' U)2 F' U' F</strong></td>    </tr>  </tbody></table><h1 id="OLL"><a href="#OLL" class="headerlink" title="OLL"></a>OLL</h1><p>OLL (Orientation of the Last Layer)是魔術方塊解法中的一個重要階段。這一階段的目的是通過一系列的旋轉公式，調整最後一層的所有方塊，使頂面的顏色統一。這涉及到旋轉方塊使其頂面的顏色與魔術方塊的頂面顏色一致，而不關心方塊之間的相對位置，位置的調整留待PLL階段處理。為了減少需要記憶的公式數量，我選擇使用兩階段OLL，這涉及到使用更少的公式來進行兩次操作。首先是形成一個頂面十字，然後再將其餘方塊調整到正確的方向。</p><h2 id="OLL第一階段"><a href="#OLL第一階段" class="headerlink" title="OLL第一階段"></a>OLL第一階段</h2><table width="100%">  <thead>    <tr>      <th width="33%">邊塊單點</th>      <th width="33%">邊塊直線</th>      <th width="33%">邊塊L形</th>    </tr>  </thead>  <tbody>    <tr>      <!-- <td width="33%"><img src="http://cube.rider.biz/visualcube.php?fmt=svg&size=150&pzl=3&bg=t&view=plan&fd=nnnnunnnnnnnnnnnnnnnnnnnnnndddddddddnnnnnnnnnnnnnnnnnn"/></td> -->      <td width="33%"><img src="/Yang-Chinese-Blog/post/1635b73a/oll-1-1.png"/></td>      <!-- <td width="33%"><img src="http://cube.rider.biz/visualcube.php?fmt=svg&size=150&pzl=3&bg=t&view=plan&fd=nnnuuunnnnnnnnnnnnnnnnnnnnndddddddddnnnnnnnnnnnnnnnnnn"/></td> -->      <td width="33%"><img src="/Yang-Chinese-Blog/post/1635b73a/oll-1-2.png"/></td>      <!-- <td width="33%"><img src="http://cube.rider.biz/visualcube.php?fmt=svg&size=150&pzl=3&bg=t&view=plan&fd=nnnnuununnnnnnnnnnnnnnnnnnndddddddddnnnnnnnnnnnnnnnnnn"/></td> -->      <td width="33%"><img src="/Yang-Chinese-Blog/post/1635b73a/oll-1-3.png"/></td>    </tr>    <tr>      <td width="33%" style="text-align: center;"><strong>F (R U R' U') S (R U R' U') Fw'</strong></td>      <td width="33%" style="text-align: center;"><strong>F (R U R' U') F'</strong></td>      <td width="33%" style="text-align: center;"><strong>Fw (R U R' U') Fw'</strong></td>    </tr>  </tbody></table><h2 id="OLL第二階段"><a href="#OLL第二階段" class="headerlink" title="OLL第二階段"></a>OLL第二階段</h2><table width="100%">  <thead>    <tr>      <th width="50%">角塊3翻I</th>      <th width="50%">角塊3翻II</th>    </tr>  </thead>  <tbody>    <tr>      <!-- <td width="50%"><img src="http://cube.rider.biz/visualcube.php?fmt=svg&size=150&pzl=3&bg=t&view=plan&fd=nuuuuunununnnnnnnnunnnnnnnndddddddddunnnnnnnnnnnnnnnnn"/></td> -->      <td width="50%"><img src="/Yang-Chinese-Blog/post/1635b73a/oll-2-1.png"/></td>      <!-- <td width="50%"><img src="http://cube.rider.biz/visualcube.php?fmt=svg&size=150&pzl=3&bg=t&view=plan&fd=uunuuununnnunnnnnnnnunnnnnndddddddddnnunnnnnnnnnnnnnnn"/></td> -->      <td width="50%"><img src="/Yang-Chinese-Blog/post/1635b73a/oll-2-2.png"/></td>    </tr>    <tr>      <td width="50%" style="text-align: center;"><strong>R U2 R' U' R U' R'</strong></td>      <td width="50%" style="text-align: center;"><strong>L' U2 L U L' U L</strong></td>    </tr>  </tbody></table><table width="100%">  <thead>    <tr>      <th width="50%">角塊4翻I</th>      <th width="50%">角塊4翻II</th>    </tr>  </thead>  <tbody>    <tr>      <!-- <td width="50%"><img src="http://cube.rider.biz/visualcube.php?fmt=svg&size=150&pzl=3&bg=t&view=plan&fd=nunuuununnnnnnnnnnununnnnnndddddddddnnnnnnnnnununnnnnn"/></td> -->      <td width="50%"><img src="/Yang-Chinese-Blog/post/1635b73a/oll-2-3.png"/></td>      <!-- <td width="50%"><img src="http://cube.rider.biz/visualcube.php?fmt=svg&size=150&pzl=3&bg=t&view=plan&fd=nunuuununnnnnnnnnnnnunnnnnndddddddddununnnnnnunnnnnnnn"/></td> -->      <td width="50%"><img src="/Yang-Chinese-Blog/post/1635b73a/oll-2-4.png"/></td>    </tr>    <tr>      <td width="50%" style="text-align: center;"><strong>F (R U R' U')3 F'</strong></td>      <td width="50%" style="text-align: center;"><strong>R U2 R2 U' R2 U' R2 U2 R</strong></td>    </tr>  </tbody></table><table width="100%">  <thead>    <tr>      <th width="33%">角塊2翻I</th>      <th width="33%">角塊2翻II</th>      <th width="33%">角塊2翻III</th>    </tr>  </thead>  <tbody>    <tr>      <!-- <td width="33%"><img src="http://cube.rider.biz/visualcube.php?fmt=svg&size=150&pzl=3&bg=t&view=plan&fd=uunuuunuunnunnnnnnunnnnnnnndddddddddnnnnnnnnnnnnnnnnnn"/></td> -->      <td width="33%"><img src="/Yang-Chinese-Blog/post/1635b73a/oll-2-5.png"/></td>      <!-- <td width="33%"><img src="http://cube.rider.biz/visualcube.php?fmt=svg&size=150&pzl=3&bg=t&view=plan&fd=nuuuuunuunnnnnnnnnunnnnnnnndddddddddnnnnnnnnnnnunnnnnn"/></td> -->      <td width="33%"><img src="/Yang-Chinese-Blog/post/1635b73a/oll-2-6.png"/></td>      <!-- <td width="33%"><img src="http://cube.rider.biz/visualcube.php?fmt=svg&size=150&pzl=3&bg=t&view=plan&fd=nunuuuuuunnnnnnnnnnnnnnnnnndddddddddnnnnnnnnnununnnnnn"/></td> -->      <td width="33%"><img src="/Yang-Chinese-Blog/post/1635b73a/oll-2-7.png"/></td>    </tr>    <tr>      <td width="33%" style="text-align: center;"><strong>L' B' R' B L B' R B</strong></td>      <td width="33%" style="text-align: center;"><strong>L' B' R B L B' R' B</strong></td>      <td width="33%" style="text-align: center;"><strong>R2 D' R U2 R' D R U2 R</strong></td>    </tr>  </tbody></table><h1 id="PLL"><a href="#PLL" class="headerlink" title="PLL"></a>PLL</h1><p>在魔術方塊的PLL (Permutation of the Last Layer)階段，我們的目標是將最後一層的方塊全部排列到正確的位置上。本篇我們會使用兩段式PLL。這個策略將最後一層的置換分為兩個階段來完成。在這種策略下，解題者會先確定最後一層所有<em><strong>角塊</strong></em>的正確位置，然後再進行<em><strong>邊塊</strong></em>的置換。</p><h2 id="PLL第一階段"><a href="#PLL第一階段" class="headerlink" title="PLL第一階段"></a>PLL第一階段</h2><p>PLL第一階段會先確定最後一層所有<em><strong>角塊</strong></em>都到正確位置。第一階段只會有兩種情況：無一側角落同色或是有一側角落同色。</p><table width="100%">  <thead>    <tr>      <th width="50%">無一側角落同色</th>      <th width="50%">有一側角落同色</th>    </tr>  </thead>  <tbody>    <tr>      <!-- <td width="50%"><img src="http://cube.rider.biz/visualcube.php?fmt=svg&size=150&pzl=3&bg=t&view=plan&fd=uuuuuuuuunnnnnnnnnnnnnnnnnndddddddddnnnnnnnnnnnnnnnnnn"/></td> -->      <td width="50%"><img src="/Yang-Chinese-Blog/post/1635b73a/pll-1-1.png"/></td>      <!-- <td width="50%"><img src="http://cube.rider.biz/visualcube.php?fmt=svg&size=150&pzl=3&bg=t&view=plan&fd=uuuuuuuuunnnnnnnnnnnnnnnnnndddddddddlnlllllllnnnnnnnnn"/></td> -->      <td width="50%"><img src="/Yang-Chinese-Blog/post/1635b73a/pll-1-2.png"/></td>    </tr>    <tr>      <td width="50%" style="text-align: center;"><strong>F R U' R' U' R U R' F' (R U R' U') (R'F R F')</strong></td>      <td width="50%" style="text-align: center;"><strong>(R U R' U') R' F R2 U' R' U' R U R' F'</strong></td>    </tr>  </tbody></table><h2 id="PLL第二階段"><a href="#PLL第二階段" class="headerlink" title="PLL第二階段"></a>PLL第二階段</h2><p>PLL第二階段會確定最後一層所有<em><strong>邊塊</strong></em>都到正確位置。</p><table width="100%">  <thead>    <tr>      <th width="50%">Ua-Perm</th>      <th width="50%">Ub-Perm</th>    </tr>  </thead>  <tbody>    <tr>      <!-- <td width="50%"><img src="http://cube.rider.biz/visualcube.php?fmt=svg&size=150&pzl=3&bg=t&view=plan&alg=M2U3MU2M3U3M2&arw=U5U3-s7,U7U5-s7,U3U7-s7"/></td> -->      <td width="50%"><img src="/Yang-Chinese-Blog/post/1635b73a/pll-ua.png"/></td>      <!-- <td width="50%"><img src="http://cube.rider.biz/visualcube.php?fmt=svg&size=150&pzl=3&bg=t&view=plan&alg=M2UMU2M3UM2&arw=U3U5-s7,U5U7-s7,U7U3-s7"/></td> -->      <td width="50%"><img src="/Yang-Chinese-Blog/post/1635b73a/pll-ub.png"/></td>    </tr>    <tr>      <td width="50%" style="text-align: center;"><strong>M2 U M U2 M' U M2</strong></td>      <td width="50%" style="text-align: center;"><strong>M2 U' M U2 M' U' M2</strong></td>    </tr>  </tbody></table><table width="100%">  <thead>    <tr>      <th width="50%">H-Perm</th>      <th width="50%">Z-Perm</th>    </tr>  </thead>  <tbody>    <tr>      <!-- <td width="50%"><img src="http://cube.rider.biz/visualcube.php?fmt=svg&size=150&pzl=3&bg=t&view=plan&alg=M2U(M2U2M2)UM2&arw=U1U7,U7U1,U3U5,U5U3"/></td> -->      <td width="50%"><img src="/Yang-Chinese-Blog/post/1635b73a/pll-h.png"/></td>      <!-- <td width="50%"><img src="http://cube.rider.biz/visualcube.php?fmt=svg&size=150&pzl=3&bg=t&view=plan&alg=M3UM2UM2UM3U2M2U&arw=U1U5,U5U1,U3U7,U7U3"/></td> -->      <td width="50%"><img src="/Yang-Chinese-Blog/post/1635b73a/pll-z.png"/></td>    </tr>    <tr>      <td width="50%" style="text-align: center;"><strong>M2 U (M2 U2 M2) U M2</strong></td>      <td width="50%" style="text-align: center;"><strong>M' U (M2 U M2 U) M' U2 M2</strong></td>    </tr>  </tbody></table><h1 id="結語"><a href="#結語" class="headerlink" title="結語"></a>結語</h1><p>練習是達到高效解題的關鍵。因為每一次的嘗試都讓我們更接近成為魔術方塊高手的目標。希望這個部落格能啟發讀者的魔術方塊探索之旅，解開更多的可能性。如果未來有更快的魔術方塊解法，我也會在此分享。</p><h1 id="References"><a href="#References" class="headerlink" title="References"></a>References</h1><ol><li><a href="https://1hrbld.tw/category/algdb/3x3-pll-algs/">https://1hrbld.tw/category/algdb/3x3-pll-algs/</a></li><li><a href="http://cube.rider.biz/visualcube.php">http://cube.rider.biz/visualcube.php</a></li><li><a href="https://chiacube.tw/Basic/Rotate">https://chiacube.tw/Basic/Rotate</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> 生活 </category>
          
          <category> 娛樂 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 魔術方塊 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SVD的微分推導</title>
      <link href="/Yang-Chinese-Blog/post/b8597833.html"/>
      <url>/Yang-Chinese-Blog/post/b8597833.html</url>
      
        <content type="html"><![CDATA[<p>最近剛好做的研究題目跟SVD有關，需要把SVD應用在神經網路裡面。所以就想說手推一下SVD的導數，並把它紀錄下來，以免之後老年癡呆都忘光光。想要看懂這篇的人也要有一點心理準備，等等的數學真的很不友善，我也是花了好久的時間才整理完這篇文章。</p><h1 id="奇異值分解"><a href="#奇異值分解" class="headerlink" title="奇異值分解"></a>奇異值分解</h1><p>奇異值分解(Singular Value Decomposition, SVD)是線性代數裡邊一個重要的主題，主要就是在進行任意矩陣分解。在信號處理、圖像修復、數據壓縮、降噪、統計學有重要應用。</p><h2 id="SVD分解"><a href="#SVD分解" class="headerlink" title="SVD分解"></a>SVD分解</h2><p>設$A$為一個$m \times n$的實矩陣，且$rank(A) &#x3D; r$，則full SVD具有以下形式：</p><p>\begin{equation}<br>   A &#x3D; U \Sigma V^T<br>   \label{eq:svd}<br>\end{equation}</p><p>其中$U \in \mathbb{R}^{m \times m}$、$\Sigma \in \mathbb{R}^{m \times n}$、$V \in \mathbb{R}^{n \times n}$。方陣$U$和$V$都是實正交矩陣(orthogonal matrix)。這邊我只考慮compact SVD，也就是$A &#x3D; U_r \Sigma_r V^T_r$。現在的三個矩陣維度分別為$U \in \mathbb{R}^{m \times r}$、$\Sigma \in \mathbb{R}^{r \times r}$、$V \in \mathbb{R}^{r \times n}$。矩陣的秩(rank)代表的是對存儲在矩陣$A$中的獨特信息的量，rank越高則信息越多。</p><h2 id="SVD求導"><a href="#SVD求導" class="headerlink" title="SVD求導"></a>SVD求導</h2><p>既然我們知道了$rank(A) &#x3D; r$，則$r \leq min(m, n)$。我們還知道$U$和$V$都是實正交，則</p><p>\begin{equation}<br>    U^T U &#x3D; V^T V &#x3D; I_r<br>    \label{eq:constraint}<br>\end{equation}</p><p>現在$A$的導數可以寫成</p><p>\begin{equation}<br>   dA &#x3D; dU \Sigma V^T + U d\Sigma V^T + U \Sigma dV^T<br>   \label{eq:diff-svd}<br>\end{equation}</p><p>在限制式$\ref{eq:constraint}$中，我們可以先對$U$求導，得到</p><p>\begin{equation}<br>   dU^T U + U^T dU &#x3D; 0<br>\end{equation}</p><p>並且假設一個新的矩陣$d\Omega_U &#x3D; U^T dU$。因為$d\Omega_U &#x3D; U^T dU &#x3D; - dU^T U$，所以我們可以知道$d\Omega$是一個反對稱矩陣(skew-symmetric)。類似地，我們可以得到$d\Omega_V &#x3D; V^T dV &#x3D; - dV^T V$，所以$d\Omega_V$也是一個反對稱矩陣。</p><p>對矩陣$A$左乘$U^T$並且右乘$V$，我們可以得到</p><p>\begin{equation}<br>\begin{aligned}<br>    U^T dA V &amp;&#x3D; U^T dU \Sigma V^T V + U^T U d\Sigma V^T V + U^T U \Sigma dV^T V \\<br>             &amp;&#x3D; d\Omega_U \Sigma + d\Sigma + \Sigma d\Omega_V^T<br>\end{aligned}<br>\label{eq:diff-svd-dp}<br>\end{equation}</p><p>現在我們定義$dP \equiv U^T dA V$，且使用$X \circ Y$來表示$X$和$Y$的Hadamard product。我們現在要分別去算$dP$斜對角元素和非斜對角元素的值。首先，我們求得$dP$斜對角元素為</p><p>\begin{equation}<br>   I_r \circ dP &#x3D; d\Sigma<br>   \label{eq:diff-svd-diagonal}<br>\end{equation}</p><p>且$dP$的非斜對角元素為</p><p>\begin{equation}<br>\begin{aligned}<br>   \bar{I_r} \circ dP &amp;&#x3D; d\Omega_U \Sigma + \Sigma d\Omega_V^T \\<br>                         &amp;&#x3D; d\Omega_U \Sigma - \Sigma d\Omega_V<br>\end{aligned}<br>\label{eq:diff-svd-dp-nondiagonal}<br>\end{equation}</p><p>由此可得$dP^T$的非斜對角元素為</p><p>\begin{equation}<br>   \bar{I_r} \circ dP^T &#x3D; - \Sigma d\Omega_U + d\Omega_V \Sigma<br>   \label{eq:diff-svd-dpt-nondiagonal}<br>\end{equation}</p><p>現在我們對式子$\ref{eq:diff-svd-dp-nondiagonal}$右乘$\Sigma$，並對式子$\ref{eq:diff-svd-dpt-nondiagonal}$左乘$\Sigma$，然後做相加可得</p><p>\begin{equation}<br>\begin{aligned}<br>    \bar{I_r} \circ (dP \Sigma + \Sigma dP^T) &amp;&#x3D; (d\Omega_U \Sigma^2 + \Sigma d\Omega_V^T \Sigma) + (- \Sigma^2 d\Omega_U + \Sigma d\Omega_V \Sigma) \\<br>    &amp;&#x3D; (d\Omega_U \Sigma^2 - \Sigma^2 d\Omega_U) + (\Sigma d\Omega_V^T \Sigma + \Sigma d\Omega_V \Sigma) \\<br>    &amp;&#x3D; d\Omega_U \Sigma^2 - \Sigma^2 d\Omega_U<br>\end{aligned}<br>\end{equation}</p><p>最終可以得到</p><p>\begin{equation}<br>    d\Omega_U &#x3D; F \circ (dP \Sigma + \Sigma dP^T)<br>    \label{eq:omega-u}<br>\end{equation}</p><p>其中</p><p>\begin{equation}<br>    F &#x3D;<br>    \begin{cases}<br>      \frac{1}{\sigma_j^2 - \sigma_i^2} &amp; i \neq j \\<br>      0 &amp; i &#x3D; j<br>    \end{cases}<br>\end{equation}</p><p>藉由類似的推導，我們也可以得到</p><p>\begin{equation}<br>    d\Omega_V &#x3D; F \circ (\Sigma dP + dP^T \Sigma)<br>    \label{eq:omega-v}<br>\end{equation}</p><p>因為$d\Omega_U &#x3D; U^T dU$，所以藉由左乘$U$我們得到$dU &#x3D; U d\Omega_U$。</p><p>再繼續更深入的SVD導數推導之前，我們要先了解一些正交補餘(orthogonal complement)和投影矩陣(projection matrix)的性質。假設$U$的正交補餘矩陣為$U_{\bot}$且維度為$m \times (m-r)$，其中$U_{\bot}$可以藉由Gram-Schmidt process算出，這邊就不再詳細介紹這個算法。另外，投影矩陣$H$必須滿足$H^2 &#x3D; H$和$H^T &#x3D; H$，也就是自己的平方和自己的轉置都必須是自己。現在我們要來證明$U_{\bot} U_{\bot}^{T}$和$I - U U^{T}$都是投影矩陣。</p><p>\begin{equation}<br>    (U_{\bot} U_{\bot}^{T})^2 &#x3D; U_{\bot} (U_{\bot}^{T} U_{\bot}) U_{\bot}^{T} &#x3D; U_{\bot} U_{\bot}^{T}<br>\end{equation}</p><p>\begin{equation}<br>    (U_{\bot} U_{\bot}^{T})^T &#x3D; (U_{\bot}^{T})^T (U_{\bot})^T &#x3D; U_{\bot} U_{\bot}^{T}<br>\end{equation}</p><p>\begin{equation}<br>    (I - U U^{T})^2 &#x3D; I - 2 U U^{T} + U U^{T} U U^{T} &#x3D; I - U U^{T}<br>\end{equation}</p><p>\begin{equation}<br>    (I - U U^{T})^T &#x3D; (I - U U^{T})<br>\end{equation}</p><p>除此之外，我們還必須了解$U$和$U_{\bot}$是否可以組成整個生成空間。我們先假設這句話為真，那麼對於任何一個向量空間都必須是$U$和$U_{\bot}$的線性組合，也就是$S &#x3D; aU + bU_{\bot}$，其中$a, b$為純量、$S$為一矩陣。我們先將$S$透過投影向量$U U^T$映射到$U$的行空間：</p><p>\begin{equation}<br>    U U^T S &#x3D; U U^T (aU + bU_{\bot}) &#x3D; a U (U^T U)  + b U_{\bot} (U^T U_{\bot}) &#x3D; a U<br>\end{equation}</p><p>其中$U^T U &#x3D; I$($U$為正交矩陣)，還有$U^T U_{\bot} &#x3D; 0$(因為$U$和$U_{\bot}$正交)。類似地，我們也可以將$S$透過投影向量$U_{\bot} U_{\bot}^T$映射到$U_{\bot}$的行空間：</p><p>\begin{equation}<br>    U_{\bot} U_{\bot}^T S &#x3D; U_{\bot} U_{\bot}^T (a U + b U_{\bot}) &#x3D; a U_{\bot} (U_{\bot}^T U) + b U_{\bot} (U_{\bot}^T U_{\bot}) &#x3D; b U_{\bot}<br>\end{equation}</p><p>合在一起看的話就是：</p><p>\begin{equation}<br>\begin{aligned}<br>    (U U^T + U_{\bot} U_{\bot}^T) S &amp;&#x3D; U U^T S + U_{\bot} U_{\bot}^T S \\<br>                                    &amp;&#x3D; a U + b U_{\bot} \\<br>                                    &amp;&#x3D; I S<br>\end{aligned}<br>\end{equation}</p><p>所以，我們可以得到$U U^T + U_{\bot} U_{\bot}^T$就是一個identity matrix。我們可以寫成以下恆等式：</p><p>\begin{equation}<br>    U_{\bot} U_{\bot}^T &#x3D; I - U U^T<br>\end{equation}</p><p>回歸到SVD的求導。為了求$dA$(式子\ref{eq:diff-svd})，我們需要算出$dU$、$d\Sigma$、$dV^T$。可以想像把SVD視為一種函示映射$f$，然後對輸入矩陣$A$增加擾動$dA$。那也就相當於對生成$A$的行空間的$U$進行擾動$dU$、對生成$A$的列空間的$V$進行擾動$dV$。不失一般性的，我們先看$dU$。假設$dU$在$U$的整個行空間($m \times m$)進行擾動，其中還可以分解為在$m \times r$和$m \times (m-r)$的部分進行擾動。所以我們可以寫成以下式子：</p><p>\begin{equation}<br>    dU &#x3D; U d\Omega_U + U_{\bot} dK_U<br>    \label{eq:du}<br>\end{equation}</p><p>其中我們已經求出$d\Omega_U$(式子\ref{eq:omega-u})，現在需要去解$dK_U$。我們對$dA$左乘一個$U_{\bot}^{T}$得到：</p><p>\begin{equation}<br>\begin{aligned}<br>    U_{\bot}^{T} dA &amp;&#x3D; U_{\bot}^{T} dU \Sigma V^T + U_{\bot}^{T} U d\Sigma V^T + U_{\bot}^{T} U \Sigma dV^T \\<br>                    &amp;&#x3D; U_{\bot}^{T} dU \Sigma V^T \\<br>                    &amp;&#x3D; U_{\bot}^{T} (U d\Omega_U + U_{\bot} dK_U) \Sigma V^T \\<br>                    &amp;&#x3D; (U_{\bot}^{T} U d\Omega_U + U_{\bot}^{T} U_{\bot} dK_U) \Sigma V^T \\<br>                    &amp;&#x3D; dK_U \Sigma V^T<br>\end{aligned}<br>\label{eq:compute-dk-u}<br>\end{equation}</p><p>整理一下式子\ref{eq:compute-dk-u}就可以得到$dK_U$：</p><p>\begin{equation}<br>    dK_U &#x3D; U_{\bot}^{T} dA V \Sigma^{-1}<br>    \label{eq:dk-u}<br>\end{equation}</p><p>同理，我們可以去算$dV$</p><p>\begin{equation}<br>    dV &#x3D; V d\Omega_V + V_{\bot} dK_V<br>    \label{eq:dv}<br>\end{equation}</p><p>然後得到$dK_V$</p><p>\begin{equation}<br>    dK_V &#x3D; V_{\bot}^{T} dA^T U \Sigma^{-1}<br>    \label{eq:dk-v}<br>\end{equation}</p><p>把式子\ref{eq:omega-u}和式子\ref{eq:dk-u}代入\ref{eq:du}可以得到$dU$，把式子\ref{eq:omega-v}和式子\ref{eq:dk-v}代入\ref{eq:dv}可以得到$dV$。</p><p>\begin{equation}<br>    dU &#x3D; U (F \circ (U^T dA V \Sigma + \Sigma V^T dA^T U)) + (I_m - U U^T) dA V \Sigma^{-1}<br>\end{equation}</p><p>\begin{equation}<br>    d\Sigma &#x3D; I_r \circ (U^T dA V)<br>\end{equation}</p><p>\begin{equation}<br>    dV &#x3D; V (F \circ (\Sigma U^T dA V + V^T dA^T U \Sigma)) + (I_n - V V^T) dA^T U \Sigma^{-1}<br>\end{equation}</p><h1 id="主成分分析"><a href="#主成分分析" class="headerlink" title="主成分分析"></a>主成分分析</h1><p>在多元統計分析中，主成分分析(Principal Components Analysis, PCA)是一種統計分析和數據降維的方法。數學定義上，PCA的基本思想是使用一個正交化線性轉換把原始數據(sample matrix)轉換到一個新的座標系統上，並且投影在新的座標後仍保留數據最大的變異。換句話說，這一數據的任何投影的第一大變異數在第一個坐標上，第二大變異數在第二個坐標上，依次類推。</p><h2 id="預備知識"><a href="#預備知識" class="headerlink" title="預備知識"></a>預備知識</h2><p>首先，我們要先了解怎麼對數據做中心化(centralisation)。</p><p>\begin{equation}<br>X_{n \times d} &#x3D;<br>    \begin{pmatrix}<br>            x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1d} \\<br>            x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2d} \\<br>            \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\<br>            x_{n1} &amp; x_{n2} &amp; \cdots &amp; x_{nd}<br>    \end{pmatrix}<br>\end{equation}</p><p>\begin{equation}<br>\mu_{d \times 1} &#x3D;<br>    \begin{pmatrix}<br>            \frac{1}{n} \sum\limits_{i&#x3D;1}^{n} x_{i1} \\<br>            \vdots \\<br>            \frac{1}{n} \sum\limits_{i&#x3D;1}^{n} x_{in}<br>    \end{pmatrix}<br>\end{equation}</p><p>對每一行操作特徵零均值化：</p><p>\begin{equation}<br>\begin{aligned}<br>\tilde{X}<br>    &amp;&#x3D; X - \mathbb{1}_{n \times 1} \mu^T \\<br>    &amp;&#x3D; \begin{pmatrix} x_1 &amp; \cdots &amp; x_d \end{pmatrix} - \begin{pmatrix} \frac{1}{n} \sum\limits_{i&#x3D;1}^{n} x_{i1} &amp; \cdots &amp; \frac{1}{n} \sum\limits_{i&#x3D;1}^{n} x_{id} \end{pmatrix} \\<br>    &amp;&#x3D; \begin{pmatrix}<br>            x_{11} - \frac{1}{n} \sum\limits_{i&#x3D;1}^{n} x_{i1} &amp; \cdots &amp; x_{1d} - \frac{1}{n} \sum\limits_{i&#x3D;1}^{n} x_{id} \\<br>            \vdots &amp; \ddots &amp; \vdots \\<br>            x_{n1} - \frac{1}{n} \sum\limits_{i&#x3D;1}^{n} x_{i1} &amp; \cdots &amp; x_{nd} - \frac{1}{n} \sum\limits_{i&#x3D;1}^{n} x_{id}<br>        \end{pmatrix} \\<br>    &amp;&#x3D; \begin{pmatrix}<br>            (1 - \frac{1}{n}) x_{11} - \cdots - \frac{1}{n} x_{n1} &amp; \cdots &amp; (1 - \frac{1}{n}) x_{1d} - \cdots - \frac{1}{n} x_{nd} \\<br>            \vdots &amp; \ddots &amp; \vdots \\<br>            - \frac{1}{n} x_{11} - \cdots + (1 - \frac{1}{n}) x_{n1} &amp; \cdots &amp; - \frac{1}{n} x_{1d} - \cdots + (1 - \frac{1}{n}) x_{nd}<br>        \end{pmatrix} \\<br>    &amp;&#x3D; \begin{pmatrix}<br>            1 - \frac{1}{n} &amp; - \frac{1}{n} &amp; \cdots &amp; - \frac{1}{n} \\<br>            - \frac{1}{n} &amp; 1 - \frac{1}{n} &amp; \cdots &amp; - \frac{1}{n} \\<br>            \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\<br>            - \frac{1}{n} &amp; - \frac{1}{n} &amp; \cdots &amp; 1 - \frac{1}{n}<br>        \end{pmatrix} \cdot \begin{pmatrix} x_1 &amp; \cdots &amp; x_d \end{pmatrix} \\<br>    &amp;&#x3D; (I_n - \frac{1}{n} \mathbb{1}_{n \times n}) \cdot X_{n \times d} \\<br>    &amp;&#x3D; \tilde{I}_{n \times n} \cdot X_{n \times d}<br>\end{aligned}<br>\end{equation}</p><p>其中<a href="https://en.wikipedia.org/wiki/Centering_matrix">居中矩陣</a>(centering matrix)是一個正交投影矩陣(orthogonal projection matrix)滿足：</p><p>\begin{equation}<br>    \tilde{I} &#x3D; \tilde{I}^2 &#x3D; \tilde{I}^T<br>\end{equation}</p><p>第二個要會的是算一下斜方差矩陣(sample covariance matrix)。</p><p>\begin{equation}<br>\begin{aligned}<br>    C &amp;&#x3D; \frac{1}{n} \sum_{i&#x3D;1}^{n} (x_i - \mu) (x_i - \mu)^T \\<br>      &amp;&#x3D; \frac{1}{n} \tilde{X}^T \tilde{X} \\<br>      &amp;&#x3D; \frac{1}{n} (\tilde{I} X)^T (\tilde{I} X) \\<br>      &amp;&#x3D; \frac{1}{n} X^T \tilde{I}^T \tilde{I} X \\<br>      &amp;&#x3D; \frac{1}{n} X^T \tilde{I} X<br>\end{aligned}<br>\end{equation}</p><h2 id="PCA思想"><a href="#PCA思想" class="headerlink" title="PCA思想"></a>PCA思想</h2><p>假如原始的樣本$X \in \mathbb{R}^{n \times d}$($n$個數據點且特徵維度是$d$)。單看其中一筆數據$x_i$在座標$v \in \mathbb{R}^{d}$上做投影，則會得到</p><p>\begin{equation}<br>    proj_{v} x_i &#x3D; \frac{v^{T} x_{i}}{\lVert v \rVert^2} v<br>\end{equation}</p><p>不失一般性，我們假設$v$是單位向量，則可以得到投影後的數據點是$(v^T x_i) v$。那麼我們可以得到去中心化後的數據的方差為：</p><p>\begin{equation}<br>\begin{aligned}<br>    \frac{1}{n} \sum_{i&#x3D;1}^{n} (\tilde{x}_i^T v - 0)^2<br>        &amp;&#x3D; \frac{1}{n} \sum_{i&#x3D;1}^{n} (\tilde{x}_i^T v)^T (\tilde{x}_i^T v) \\<br>        &amp;&#x3D; \frac{1}{n} \sum_{i&#x3D;1}^{n} v^T \tilde{x}_i \tilde{x}_i^T v \\<br>        &amp;&#x3D; v^T (\frac{1}{n} \sum_{i&#x3D;1}^{n} \tilde{x}_i \tilde{x}_i^T) v \\<br>        &amp;&#x3D; v^T (\frac{1}{n} \tilde{X}^T \tilde{X}) v \\<br>        &amp;&#x3D; v^T C v<br>\end{aligned}<br>\end{equation}</p><p>我們希望可以最大化投影後的數據方差，則可以利用拉格朗日函數建立目標函數：</p><p>\begin{equation}<br>    \mathcal{L}(v) &#x3D; - v^T C v + \lambda (v^T v - 1)<br>\end{equation}</p><p>對$v$求導可以得到：</p><p>\begin{equation}<br>    \frac{\partial \mathcal{L}}{\partial v} &#x3D; -2 C v + 2 \lambda v &#x3D; 0<br>\end{equation}</p><p>最終得到：</p><p>\begin{equation}<br>    C v &#x3D; \lambda v<br>\end{equation}</p><p>所以，我們可以得到$v$是$C$的特徵向量，$\lambda$是對應的特徵向量的特徵值。要是想要最大化$v^T C v$，那就必須要最大化$\lambda$，因為$v^T C v &#x3D; v^T \lambda v &#x3D; \lambda v^T v &#x3D; \lambda$。</p><p>這裡還需要證明一下另外一個重要的性質。對於$X$的第$j$個主要成分$v_{j}$會是斜方差矩陣$C$第$j$大的特徵向量，對應的$\lambda_{j}$是第$j$大的特徵值。這邊會證明$j&#x3D;2$的例子：</p><p>\begin{equation}<br>    v_2 &#x3D; \underset{\lVert v \rVert^2 &#x3D; 1, v_1^T v &#x3D; 0}{\operatorname{arg max}} v^T C v<br>\end{equation}</p><p>一樣列出拉格朗日函數的目標函數</p><p>\begin{equation}<br>    \mathcal{L}(v) &#x3D; - v^T C v + \alpha_1 (v^T v - 1) + \alpha_2 (v_{1}^{T} v)<br>\end{equation}</p><p>最小化$\mathcal{L}(v)$可以得到</p><p>\begin{equation}<br>    -2 C v + 2 \alpha_1 v + \alpha_2 v_1 &#x3D; 0<br>\end{equation}</p><p>所以$\alpha_2 &#x3D; 0$且$C v &#x3D; \alpha_1 v$。想要最大化$v^T C v$的話，$v_2$就必須是第二大的特徵向量且$\alpha_1 &#x3D; \lambda_2$。</p><h1 id="總結"><a href="#總結" class="headerlink" title="總結"></a>總結</h1><p>首先我要恭喜有成功看完這篇文章並且沒有腦死的各位。<br>之後我投的paper有成功上岸，我會再寫一篇文章來分享。</p><h1 id="References"><a href="#References" class="headerlink" title="References"></a>References</h1><ol><li>Edelman et al., The geometry of algorithms with orthogonality constraints, 1998</li><li>Townsend, Differentiating the singular value decomposition, 2016</li><li>Wang et al., Robust Differentiable SVD, 2021</li></ol>]]></content>
      
      
      <categories>
          
          <category> 科研 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SVD </tag>
            
            <tag> 矩陣分解 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>英國Research Intern的經歷</title>
      <link href="/Yang-Chinese-Blog/post/a949fbb9.html"/>
      <url>/Yang-Chinese-Blog/post/a949fbb9.html</url>
      
        <content type="html"><![CDATA[<p>這邊來稍微紀錄一下我在英國實習的經過。想當初從Google上面搜尋別人分享的海外實習經歷，都只能跳出一些留學仲介發的廣告文，或是那種求職網站給的JD(job describtion)。我就想說我要分享給其他有需要的人們，或許某些正在英國找實習的人可以從中找到啟發。</p><h1 id="VoiceBase-Centre"><a href="#VoiceBase-Centre" class="headerlink" title="VoiceBase Centre"></a>VoiceBase Centre</h1><p>在英國讀碩士的期間，我做了兩份實習。</p><p>第一份實習，算是非常非常的幸運，可以說是被我撿到的。</p><h2 id="運氣爆棚"><a href="#運氣爆棚" class="headerlink" title="運氣爆棚"></a>運氣爆棚</h2><p>剛開學那時候，整個學院大概有200位學生要準備去搶碩士題目。但是我對大部分的題目都是興致缺缺。所以我就選擇自己寫了一份research proposal，貼在學校的網站布告欄上，希望有教授對我的topic感興趣。我給大約20位教授發了信，跟他們自薦了一番，希望我可以成為他們的指導學生。不過到最後，只有三位教授給我回了信。</p><p>大約過了一周，SpandH組的Thomas Hain教授也給我發了封信。他說非常抱歉沒有在選題目的deadline之前給我回信，因為他人不舒服無法給我回應(我猜應該是covid)。Thomas跟我說他實驗室有研究實習的缺，問我有沒有興趣。我當時高興到飛天，馬上就給了他一個正面回應。</p><h2 id="語音識別面試"><a href="#語音識別面試" class="headerlink" title="語音識別面試"></a>語音識別面試</h2><p>過了兩三天，Thomas就說想跟我面試一下，看一下我的research ability。在面試的過程中，Mauro Nicolao和‪Md Asif Jalal‬(未來的兩位internship supervisors)也在場跟Thomas一起面試我。基本上就是一些motivations和數學相關的問題。也問了一些當時碩士課程裡面的語音相關問題，還有對深度學習神經網路的理解程度。我把當時被問的題目整理成下面的bullet points：</p><ul><li>Describe an important project you’ve worked on.</li><li>Have you ever worked on a project related to speech?</li><li>Why is it possible to use matrix decomposition to speed up the neural networks?</li><li>What else you can apply to with the help of matrix decomposition technique?</li><li>Do you know how to use speech recognition tools like HTK or Kaldi?</li></ul><p>過沒多久，我就收到了offer，也得知了要在裡面做什麼樣的project。這是有關於robust channel demixing的語音任務。如果之後有人有興趣，我也會對此單獨發一篇文來分享一下。</p><p>我知道這份實習的前半部分一定會很煎熬，畢竟當時還有60學分要努力，還得每周固定跟Thomas報告我項目的進度。我還要摸熟很多我根本就沒碰過的技術，包含HPC (high performance computing)、mini-framework、linux等等。我那時也對語音領域一竅不通，也就是剛學會一些filter bank、MFCC之類的鬼東西的程度。但隨著課程的跟進和我對這些frameworks的熟悉後，我也就開始漸入佳境。</p><h1 id="eSalesHub"><a href="#eSalesHub" class="headerlink" title="eSalesHub"></a>eSalesHub</h1><p>另外一份實習，我只能說是用我之前的努力換來的回報。</p><h2 id="碩論空窗期"><a href="#碩論空窗期" class="headerlink" title="碩論空窗期"></a>碩論空窗期</h2><p>快要畢業的時候，我的指導教授Chenghua Lin對我的碩士論文挺滿意的，所以就推薦我去一間在Doncaster的公司eSalesHub做research intern。這是一間很local的英國新創。我進去的時候公司可能才創立不到半年吧。</p><p>我在那邊的主要任務就是要把machine learning導入到公司的產品生態裡面。希望可以讓公司透過一系列的machine learning算法來提升企業獲利。</p><h2 id="ML不是萬能"><a href="#ML不是萬能" class="headerlink" title="ML不是萬能"></a>ML不是萬能</h2><p>老實說，像eSalesHub這樣的新創公司有很多data相關規範，以及如何處理data的pipelines都不成熟。<strong>很多老闆都以為買台電腦，明天就可以把事情解決。</strong></p><p>我認為只有老闆懂了甚麼是AI、cloud technique、machine learning，才有可能讓技術真正落地。再來如果企業思維跟文化跟不上(例如跨部門整合)，說再多也只是徒勞。</p><h2 id="ML業務"><a href="#ML業務" class="headerlink" title="ML業務"></a>ML業務</h2><p>我在這個項目裡面負責的產品是Intent Classification in Call Centre。簡單來說，就是要把call centre接到的所有雙聲道phone calls做分類。我當時拿到的data是經過AWS轉換過後的transcription而非原始的audio data，所以我只能把它當作一個文字分類的任務來做。我的solution是把agent和customer的文字分別做encoder，再把他們的representations做fusion後丟進一個LightGBM分類器去做訓練。假如有人敲碗想知道細節的話，我之後會再發一篇來分享。</p><h2 id="實習小插曲"><a href="#實習小插曲" class="headerlink" title="實習小插曲"></a>實習小插曲</h2><p>我拿到的dataset非常的支離破碎。轉換成文字後，裡面的斷句(tokenisation)很多都是錯的，甚至ASR的結果也不正確，然後還有一堆filling words。這對於我要做一個text classifier是極度的不友善。我跟老闆還有工程團隊反應過後也沒有任何幫助或是回應。就連我希望可以拿到更多的data samples也是經過好幾個月才拿到一個不完整的。到後來因為老闆覺得維運困難，就把這個項目shutdown了。</p><p>在此奉勸想要去新創做machine learning的人，要記得在面試的時候就先問清楚裡面團隊對於data運作處理的方式，以及遇到各種情境的應對方式。不然就會落得跟我一樣的下場。</p><h1 id="結語"><a href="#結語" class="headerlink" title="結語"></a>結語</h1><p>總之，在英國的一年半裡，我過得還滿充實的。每天都是10小時以上的coding，除了睡覺吃飯以外都是在敲代碼。實習算是海龜生活的過客而已，但也因此認識了很多大佬研究員。總覺得這樣特別的經歷以後應該也很難會有了。</p>]]></content>
      
      
      <categories>
          
          <category> 生活 </category>
          
          <category> 留學 </category>
          
          <category> 工作 </category>
          
          <category> 實習 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 英國 </tag>
            
            <tag> 實習 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>踏上征途</title>
      <link href="/Yang-Chinese-Blog/post/5fec1f59.html"/>
      <url>/Yang-Chinese-Blog/post/5fec1f59.html</url>
      
        <content type="html"><![CDATA[<p>通常我們不知道未來想要做甚麼，是因為未來太遠。我們很難預測未來將發生什麼事，也很難知道自己未來的興趣和需求會是什麼。當然，這也發生在我自己身上。大學畢業後完全沒有任何想法。只知道自己不想做甚麼，而卻不清楚自己想做甚麼。寫了這篇文章，就只是想要紀錄一下未來幾年，期望我能夠做出一些改變，也同時希望能不小心刺激或是改變某些人的生活。</p><h1 id="在數學系的生活"><a href="#在數學系的生活" class="headerlink" title="在數學系的生活"></a>在數學系的生活</h1><p>在大學期間，上的課程基本上要嘛是大家討厭的那種抽象數學，不然就是完全不知道甚麼鬼東西的邏輯推導。但，對於大家想像的數學生活枯燥乏味其實也不然，基於我的<strong>自閉</strong>性格，我覺得在追求解決方法的過程中是非常刺激的。抑或是在全班有超過90%被當的那種科目(例如代數或是高等微積分)，還能pass的那種成就感，是在其他系根本無法體驗到的。</p><p>畢業後，我就當了好幾個月的廢物。我也曾想過是否應該要念個台清交研究所來挽救頹勢，但是一想到我那不堪回首的考試經歷(免試錄取備取一落榜、基測差一分落榜、學測時體育資優考試第一名落榜、多益考試劃錯共100題)，我立馬就勸退自己，別跟自己過不去。</p><h1 id="在KKBOX的生活"><a href="#在KKBOX的生活" class="headerlink" title="在KKBOX的生活"></a>在KKBOX的生活</h1><p>還記得當時，我在104海投了一堆公司，粗略估計也有大概100間。幾乎每間公司都不鳥我這種甚麼都不會的菜鳥，除了KKBOX以外。我還歷歷在目當時在面試時被問了甚麼。我覺得實在是非常值得分享。</p><p>我當時投的職缺是Software Quality Assurance Assistant (SQA) Engineer。在面試的過程中，被問了一堆跟甚麼CI&#x2F;CD、Unit Test相關的測試問題。我的回答也是非常的一致，就是”我不會”。我猜當時的面試官鐵定也是非常傻眼，想說這個傻逼來這裡幹甚麼的。我被問的最後一題是我會不會流程圖。想當然爾，我一樣是回答”我不會”。不過面試官卻很和善的問我說：如果我教你甚麼是流程圖，你能不能做出一個登錄系統的流程圖？我就心虛的跟他說應該是沒有問題，然後手開始很抖得設計面試官要求的社群網站的登錄系統流程圖。幸好我當時的智商還在線，沒有在那邊當場丟人現眼。後來，過了兩個禮拜我就收到KKBOX的offer了。我真是又驚又喜，可能KKBOX有看出我潛在的特質？？？我就這樣抱持著去學(丟)習(臉)的心態，打包行李就這樣一個人北漂去了。中間除了技術面，也有問一些Behavioral interview questions，像是身邊的朋友會怎麼形容我這個人或是遇到難關會怎麼處理之類的行為測試問題。</p><h1 id="攻讀碩士學位的契機"><a href="#攻讀碩士學位的契機" class="headerlink" title="攻讀碩士學位的契機"></a>攻讀碩士學位的契機</h1><p>在KKBOX待了沒幾個月，我就覺得QA的工作實在是太無聊，也沒有甚麼挑戰性(希望這句話別被當時主管看到xD)。每天被無數的test cases和免費下午茶和零食轟炸，腦袋跟體重都被無限轟炸。我當時就在上班時間的時候偷偷看以後有沒有甚麼領域可以讓我轉換一下跑道。無意間發現Natural language processing (NLP)似乎挺有趣的，也剛好看到我喜歡的學校。我立馬就寄了一封信給在NAIST的Satoshi Nakamura教授，問他能不能收我當他的學生。</p><p>過不久，Satoshi Nakamura教授就真的回我信了！當下的心情實在是太激動了，馬上就衝去販賣機又拿了幾瓶養樂多慶祝了一下！不過Satoshi Nakamura教授說他下禮拜就要飛德國參加一個NLP Conference，要等三個禮拜才會回日本。我就立馬回信跟他說我後天去找他跟他聊聊！！！回完信的當下，我立馬跟我主管請假，然後就訂了兩天後的日本機票。現在回想起來真的是瘋了。</p><p>到了偏僻的奈良後，一開始還找不到學校在哪裡，還好周圍的日本人都很友善幫我指路。到了Satoshi Nakamura的研究室後，稍微觀察了一下他們研究的環境，是真的滿令人嚮往的，滿滿的研究味。</p><img src="/post/naist-lab.jpg" width="50%"><p>聊天的過程都挺愉快的，基本上就是問一些過去數學系的經歷跟現在工作的事情。後來就開始聊台灣鳳梨酥？？？Satoshi Nakamura教授到最後也說願意幫我寫Letter of Acceptance，不過我還是得參加兩個月後的入學考試。考試的內容就是筆試(微積分、微分方程、線性代數)和面試(研究計畫)。 回到台灣後，每天下班後的生活都是研讀數學到晚上12點。就這樣持續了兩個月，沒有例外。</p><h2 id="NAIST入學考試"><a href="#NAIST入學考試" class="headerlink" title="NAIST入學考試"></a>NAIST入學考試</h2><p>筆試考試的內容就是從四題(兩題微分方程和兩題線性代數)裡面挑兩題(一題微分方程和一題線性代數)出來，到台上用白板講解給台下的兩位教授。考完的當下，覺得還滿有信心可以得到滿高分的，畢竟我兩題都有解出來。</p><p>筆試完馬上就進到另外一個房間準備面試。進去後會先有一個三分鐘的自我介紹，然後才開始正式進入研究計畫(research proposal)的提問環節。我還把我當時被問的問題記了下來：</p><ol><li>Please briefly explain your research proposal.</li><li>Have you done reading lots of papers regarding to your area of specialisation?</li><li>How to utilise the mentioned model (BERT and XLNet) into your research proposal?</li><li>What else could you improve on your proposed model?</li><li>Why could mathematics profession be your strength?</li><li>What is the connection between question-answering system and your research proposal?</li><li>Could you implement your chat-bot with the state-of-the-art right now?</li></ol><p>前面的問題我還算是回答得滿有把握的。只要有把BERT和當時很紅的XLNet的paper讀過，基本上應該不會有問題。只有最後一題我真的太害怕考官會直接把一台電腦搬出來給我敲代碼，所以我就回答說我做不到。(當時HuggingFace還沒有開源他們寫的BERT代碼，Google也還沒有開源XLNet代碼)當時還被另外兩位考官(一個日本人一個印度人)調侃說數學系本來就不太會coding，我拳頭直接都硬了起來。</p><p>兩周後考試結果就出來了。我差了22分，落榜了。就在當下，我毅然決然跟我主管提出我要辭職，下定決心一定要考上國外的研究所。也就是在這個時候，我萌生了想要去英國念NLP的想法。</p><h2 id="英國碩士"><a href="#英國碩士" class="headerlink" title="英國碩士"></a>英國碩士</h2><p>辭職後，我就回到台中專心準備申請英國碩士的材料。我總共申請了11個Programmes。</p><ol><li>University of Nottingham, Machine Learning in Science</li><li>University of Nottingham, Data Science</li><li>University of Sheffield, Computer Science with Speech and Language Processing</li><li>University of Sheffield, Data Analytics</li><li>University of Warwick, Computer Science</li><li>University of Birmingham, Computer Science</li><li>University of Aston, Data Analytics</li><li>University of Essex, Big Data and Text Analytics</li><li>University of Essex, Data Science</li><li>University of Leicester, Data Analysis for Business Intelligence</li><li>University of Swansea, Data Science</li></ol><p>六間百大的申請，我在一個月內就收到四封拒信，所以我就把希望全都寄託在僅剩的Sheffield。原本想說應該希望不大的，結果竟然在12&#x2F;17的下午，我就收到Sheffeild的conditional offer！！！不過條件是要考到IELTS雅思6.5才會轉成unconditional offer。我立馬就報了兩周後的雅思考試，準備欣然應戰。</p><p>但每當我需要準備重要考試的時候，都會有意外發生。我報完考試的隔天就得流感，害我臥病在床一個禮拜，真的令人傻眼。考試當天全程咳嗽咳到尾，真的對在場所有考生非常抱歉xD</p><img src="/post/offer.jpg" width="50%"><p>非常慶幸最後也很狗屎運的拿到6.5低空飛過，也順利拿到unconditional offer。</p><h1 id="前往英國的準備"><a href="#前往英國的準備" class="headerlink" title="前往英國的準備"></a>前往英國的準備</h1><p>這整段經歷是真的一波三折，各種碰壁。為了在英國可以survive，我也做了各式各樣的準備。從了解一些英國的文化，到碩士的整個授課大綱，我都有先做了一些research。在去英國之前，我基本上就已經把我未來120學分的課程都先看了一遍，也把我碩士論文的topic也想過了。深怕我在讀碩的期間被打趴，真的是做足了功課。</p><p>另外一個更重要的事情是，雖說獨自到國外求學確實需要不少的勇氣，但更重要的是能否透過不同的教育制度，學到不同的思考模式和加強到本身的表達能力。當踏出舒適圈，受到文化衝擊，絕對可以拓展國際視野。</p><p>最後的最後，希望每位考生在考前都可以身體健康，也都能offer拿到手軟！！！祝我在英國好運！！！</p>]]></content>
      
      
      <categories>
          
          <category> 生活 </category>
          
          <category> 求學 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 日本 </tag>
            
            <tag> 英國 </tag>
            
            <tag> KKBOX </tag>
            
            <tag> 數學系 </tag>
            
            <tag> NAIST </tag>
            
            <tag> 碩士 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
